\documentclass[11pt]{scrreprt}

\renewcommand{\textfraction}{0.001}
\renewcommand{\topfraction}{0.999}   
\renewcommand{\bottomfraction}{0.999}

\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{mathtools}
\usepackage{amssymb}
\usepackage[bibencoding=utf8, backend=biber, style=numeric-comp, sorting=none, minbibnames=1, maxnames=5]{biblatex}
\addbibresource{bibliography.bib}
\usepackage{a4,color}
\usepackage{tikz}
\usepackage{pgfplots}
\pgfplotsset{compat=1.10}
\usepackage{calc}

\usepackage{booktabs,multirow}
\usepackage{newfloat}
\usepackage{caption}
\usepackage{longtable}
% \usepackage{subcaption}
\usepackage{float}
\usepackage{url}
\usepackage{listings}
\usepackage{hyperref}
\usepackage{subfig}
\usepackage{fancyhdr}
\usepackage[top=3.5cm, bottom=3.5cm, left=3cm, right=3cm]{geometry}

\pagestyle{fancy}
\fancyhead[r]{\small\leftmark}
\fancyhead[l]{\small\nouppercase\rightmark}

\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}

\usepackage{mathpazo}

\definecolor{red}{rgb}{1,0,0}
\definecolor{green}{rgb}{0,1,0}
\definecolor{blue}{rgb}{0,0,1}
\definecolor{darkblue}{rgb}{0,0,0.8}

\definecolor{yellow}{rgb}{1,1,0}
\definecolor{lightblue}{rgb}{0,1,1}
\definecolor{magenta}{rgb}{1,0,1}
\definecolor{lightgrey}{rgb}{0.5,0.5,0.5}
\definecolor{grey}{rgb}{0.35,0.35,0.35}
\definecolor{darkgrey}{rgb}{0.2,0.2,0.2}
\definecolor{ockerrot}{rgb}{0.859,0.375,0.152}

% Default fixed font does not support bold face
\DeclareFixedFont{\ttb}{T1}{txtt}{bx}{n}{12} % for bold
\DeclareFixedFont{\ttm}{T1}{txtt}{m}{n}{12}  % for normal

% Custom colors
\usepackage{color}
\definecolor{deepblue}{rgb}{0,0,0.5}
\definecolor{deepred}{rgb}{0.6,0,0}
\definecolor{deepgreen}{rgb}{0,0.5,0}

\usepackage{listings}

% Python style for highlighting
\lstset{
language=Python,
basicstyle=\ttm,
otherkeywords={self, for},             % Add keywords here
keywordstyle=\ttb\color{deepblue},
emph={MyClass,__init__, np},          % Custom highlighting
emphstyle=\ttb\color{deepred},    % Custom highlighting style
stringstyle=\color{deepgreen},
frame=tb,                         % Any extra options here
showstringspaces=false            % 
}

\DeclareFloatingEnvironment[fileext=cds,placement={!ht},name=Code Snippet]{codesnippet}

\captionsetup{margin=0pt,font=small,labelfont=sc,labelformat=simple,format=plain,indention=3mm,
 labelsep=endash,textfont=sf,font=sf,singlelinecheck=on,figurename=Fig.,tablename=Tab.}

\captionsetup[codesnippet]{margin=0pt,font=small,labelfont=sc,labelformat=simple,format=plain,indention=3mm,
 labelsep=endash,textfont=sf,font=sf,singlelinecheck=on}

\fontfamily{ppl}\selectfont

\newcommand*{\bfrac}[2]{\genfrac{\big (}{\big )}{0pt}{}{#1}{#2}}

\setlength{\parskip}{1.5ex plus 0.5ex minus 0.2ex}
\setlength{\parindent}{0pt}

% \linespread{1.5}\selectfont

\begin{document}


\begin{titlepage}
  \includegraphics[width=0.4\textwidth]{pics/uzh_logo_e_pos.pdf}
  \vspace{1cm}

  \Huge\centering New Approach for a Circle Hough Transform to Detect
        Cherenkov Rings in the LHC\textit{b} RICH detector 

  \noindent\makebox[\textwidth]{\rule{\textwidth}{0.4pt}}

\vspace{1cm}

{\centering
  \Large Master thesis\\
  of\\
  Philipp Gloor
  \vspace{1.5cm}

  \Large Mathematisch-naturwissenschaftliche Fakult채t\\
  der\\
  Universit채t Z체rich
  \vspace{2cm}

  \Large 
  Prof. Dr. P. Saha\\
  Prof. Dr. U. Straumann\\
  Dr. O. Steinkamp\\
\vspace*{\fill}
\Large Z체rich 2016


  }
\end{titlepage}
\chapter*{Abstract}
\addcontentsline{toc}{chapter}{Abstract}
This thesis explores possible algorithms for the detection of rings of Cherenkov photons which are produced by particles 
travelling through a RICH detector in the LHC\textit{b} experiment. These rings can be detected with the help of a Hough 
transform. After a brief introduction to LHC\textit{b} and the RICH detector, this thesis gives a short introduction to 
the linear Hough transform (which detects straight lines) to give a rough idea about what a Hough transform can do. 
This is followed a brief look at the circle Hough transform (which detects circles). This part is split in 3 sections, 
discussing 1D, 2D and 3D Hough transforms. The 1D Hough transform can be used when the center of the circle is given and only its radius 
needs to be found. The 2D Hough transform looks for the position of circle centers ($(x,y)$ coordinate) for a given radius. 
The 3D Hough transform is used when neither center nor radius of the ring are known. This is the case for the data from LHC\textit{b} 
where there are data points (photons from several Cherenkov rings and noise hits) and the algorithm has to find all the rings.

Apart from the standard Hough transform with a 3D accumulator space this thesis develops a new approach for a Hough transform. 
This approach works on the basis that each circle is defined by 3 points. Given 3 points one can calculate the circumcenter 
(the center of the circle we are intersted in) and the radius of the circumcircle.

For the development of these algorithms python was used in combination with different modules such as \texttt{numpy, scipy, matplotlib}. The source code for this thesis can be found on github.com~\cite{Gloor2016}.

\tableofcontents
\listoftables
\listoffigures	
\listofcodesnippets

\chapter{Introduction}
\section{LHC - Large Hadron Collider} % (fold)
\label{sec:lhc_large_hadron_collider}
\begin{figure}[htb]
  \centering
  \includegraphics[width=0.6\textwidth]{pics/lhc}
  \caption{The LHC ring with its four large experiments: ATLAS, CMS, ALICE and LHC\textit{b}}
  \label{fig:lhc}
\end{figure}

The Large Hadron Collider (LHC) is the largest and highest-energy particle accelerator in the world colliding protons on protons
at beam energies of up to $6.5$\,TeV and lead ions at beam energies up to $5.5$\,TeV/nucleon. It was built by the European 
Organisation for Nuclear Research (CERN) from 1998 to 2008. It aims to test the predictions of different theories in high-energy particle 
physics, in particular for the search of the Higgs boson (which has been confirmed last year) and signs for possible new physics beyond 
the Standard Model of particle physics. The LHC lies in a tunnel $27$\,km in circumference and up to $100$\,m below the surface of the 
French-Swiss border near Geneva. The LHC was built in collaboration with over 10000 scientists and engineers from over 100 countries. 
The accelerator has been running with a center of mass energy of $\sqrt{s} = 13$ TeV since 20 May 2015.

The LHC hosts four large experiments \parencite{Aad2008,Aamodt2008,AlvesJr2008,Collaboration2008}:

\paragraph{ATLAS/CMS}
  \begin{itemize}
    \item The two multi-purpose experiments at the LHC with the main goal of probing $p-p$ collisions for direct searches of new particles.
  \end{itemize}
\paragraph{ALICE}
  \begin{itemize}
    \item ALICE (A Large Ion Collider Experiment) is a general-purpose, heavy ion detector at the CERN LHC
    which focuses on QCD, the strong interaction sector of the Standard Model, e.g. searching for evidence for quark-gluon
    plasma.
  \end{itemize}
\paragraph{LHC\textit{b}}
  \begin{itemize}
    \item LHC\textit{b} is testing the Standard Model by confronting its predictions with precise measurements in CP
    violation and rare decays of particles containing $b$ and $c$ quarks.
  \end{itemize}



% section lhc_large_hadron_collider (end)

\section{The LHC\textit{b} experiment}

\begin{figure}[tb]
  \centering
  \includegraphics[width=\textwidth]{pics/lhcb_detector}
  \caption[LHC\textit{b} detector]{LHC\textit{b} Detector: The beams collide inside the Vertex Locator. The RICH1 is positioned before the tracking station (TT) and
  the magnet. RICH2 is set up after the magnet and the tracking stations (T1-T3) and before the calorimeters (SPD/PS, ECAL, HCAL) and muon stations (M1-M5)}
  \label{fig:lhcb}
\end{figure}

The main goal of the LHC\textit{b} experiment is the study of decays of particles containing $b$ and $\bar{b}$ quarks (such as \textit{B}-Mesons). During the $p-p$ collisions at the LHC these particles 
are produced mostly at small polar angles with respect to the beam axis. This is reflected in the design of the LHC\textit{b} detector 
which is a foward arm spectrometer 20 meters long with subdetectors arranged along the beam pipe as shown in figure \ref{fig:lhcb}.

A brief overview of the detector parts \parencite{lhcbweb}.

\paragraph{VELO} The VErtex LOcator surrounds the region where the beams collide and $b$/$\bar{b}$ pairs are produced. The VELO measures the 
distance between the $p-p$ collision point and the point where the \textit{B} particles decay. \textit{B} particles are short-lived (decaying after typically
$1$\,cm) thus their properties are not measured directly but inferred from the separation of these two points and the properties of 
their decay products.

\paragraph{RICH} The RICH detectors are built for particle identification in particular to distinguish charged kaons from pions. 
One detector on each side of the magnet is used to cover different momentum ranges. RICH detectors work by measuring emissions of 
Cherenkov radiation which is produced if a particle travels faster than the speed of light through a certain medium (often compared 
to breaking the sound barrier). The emission angle depends on the speed of the particle, so knowing the speed and the momentum (from the
curvature of the track induced by the magnet) the mass of the particle can be inferred.

\paragraph{Magnet} Particles normally move in a straight line but a magnetic field causes the path of charged particles to 
curve according to the Lorentz force 
\[
  \mathbf{F} = q\left( \mathbf{E} + \left( v\times\mathbf{B}\right)\right)
\]
thus allowing to determine the charge sign of the particle. Also the track curvature can be used to measure the momentum of the particle.

\paragraph{Tracking System} The tracking system is based on 4 planar tracking stations. It is used to determine the momentum of charged
particles by measuring the bending of the trajectory in the magnetic field. Two types of tracking detectors are used in LHC\textit{b}. In the silicon detector a passing particle generates electron-hole pairs which induce a charge on the readout strips. In the straw tube detector a particle ionises the gas molecules in gas-filled tubes which induce charges on a readout wire.

\paragraph{Calorimeters} They are designed to stop particles and measure their energy. The design of the stations is sandwich like with alternating metal and scintillator plates. Interactions in the metal plate cause a secondary shower of charged particles which induce scintillation light in the scintillator plates. The energy lost is proportional to the amount of light emmitted. Calorimetry is also the main way of identifying neutral particles (e.g. photons, neutrons).

\paragraph{Muon system}
Muons are easy to identify and play an important role in many analyses. There are five planar stations at the end of the detector each consisting of an iron absorber and a detection plane. The total area covered by these 
stations is about $435$\,m$^2$~\cite{Alves:2012ey}. The goal of the absorber is to stop all particles except muons who still can pass. The muons get detected 
in the gaseous detectors where their trajectory is measured.
% The fact that at the LHC b-hadrons are predominantly produced in the forward region was used in the construction of the detector. The \emph{LHC\textit{b}} experiment is a single arm forward spectrometer with a 4\,Tm dipole magnet and a polar angular coverage from 10 to 300 mrad in the horizontal plane (the bending plane of the dipole magnet) and 250 mrad in the vertical plane.


\subsection{Particle identification} % (fold)
\label{sub:particle_identification}

An important requirement at LHC\textit{b} is particle identification. This is handled by the calorimeters, Muon and RICH sub-detectors. The 
Calorimeters beside measuring energies and positions of electrons, photons and hadrons also provide identification of said particles e.g.
by measuring the shape of the induced showers. The Muon system identifies muons to a very high level of purity.
       
Hadron identification i.e. separation of kaons, pions and protons is  important for many analyses. The LHC\textit{b} RICH system 
provides this, covering a momentum range of approximately $1$--$100$\,GeV. It is composed of two detectors. One is positioned upstream of the 
dipole magnet and the other one is positioned downstream of the dipole magnet. Their setup is briefly described in Section~\ref{sec:rich_detector}.


% subsection particle_identification (end)

\chapter{Theory}

\section{Cherenkov radiation} % (fold)
\label{sec:cherenkov_radiation}

The speed of light in vacuum, \( \mathbf{c} = 299'792\,\text{km/s} \), is a universal physical constant. According to Einstein's special theory of relativity, 
\( c \) is the maximum speed at which all matter (or information) in the universe can travel. The speed at which light propagates in a 
medium is given by $\frac{c}{n}$, where $n$ is the refractive index of the medium and can be significantly less can \( c \).

Cherenkov radiation results when a charged particle travels through a dielectric medium with a speed greater than the speed of light 
through said medium. The velocity that must be exceeded is the phase velocity (\( v_{\text{Phase}} \text{ or short } v_{\text{P}} \)) 
and not the group velocity (\( v_{\text{Group}} = \frac{\partial \omega}{\partial k} \)),

\[ v_{\text{P}} = \frac{c}{n} = \frac{\lambda}{T}  =  \frac{\omega}{k},\]

where $\lambda$ is the wavelength of the light, $T$ the oscillation period, $\omega$ the angular frequency and $k$ the wavenumber.

As a charged particle travels through the medium, it disrupts the local electromagnetic field. If the particle travels slower than
the speed of light then the disturbance elastically relaxes to the equilibrium as the particle passes. However, if the particle 
travels at the speed $\beta\cdot c$ faster than the speed of light i.e. $\beta > 1/n$, the limited response speed of the medium means that a disturbance is left in the wake of the 
particle, and the energy in this disturbance radiates as a coherent shockwave.

\begin{figure}[htbp]
  \centering
    \begin{tikzpicture}
      \draw (-1,0) -- (6,0);
      \draw (0,0) -- (1,2) -- (5,0);
      \draw (0,0) -- (1,-2) -- (5,0);
      \draw[->, red, thick] (-1,0) -- (-0.5,0);
      \draw (0.2,0)arc[radius=.3,start angle=0,end angle=45];
      \node [left] at (0.5,1) {\footnotesize$\dfrac{c}{n}t$};
      \node [below] at (2.5 ,0) {\footnotesize$\beta c t$};
      \node [right] at (0.2,0.2) {\footnotesize$\theta$};
      \foreach \x in {0,1,...,9} {
        \draw[->,blue, thick] (1.1 + \x*0.4, 2.1 - \x*0.2)  --+ (63.435:0.3);
        \draw[->,blue, thick] (1.1 + \x*0.4, -2.1 + \x*0.2) --+ (-63.435:0.3);
      }
    \end{tikzpicture}
  \caption{The geometry of the Cherenkov radiation}
  \label{fig:cherenkov_radiation}
\end{figure}

As illustrated in Figure~\ref{fig:cherenkov_radiation}, the shockwave is emited under an angle
\begin{equation}
    \cos\theta = \frac{x_{\text{p}}}{x_{\text{em}}} = \frac{\frac{c}{n}t}{\beta c t} = \frac{1}{n\beta}
\end{equation}
with respect to the direction of flight of the particle. Figure~\ref{fig:radiators} shows the Cherenkov angle vs momentum for different particles and different radiators in LHC\textit{b}.

\begin{figure}[tb]
  \centering
  \includegraphics[width=0.8\textwidth]{pics/radiators}
  \caption{Cherenkov angle vs momentum for the different particles in different radiators}
  \label{fig:radiators}
\end{figure}

\section{RICH detector} % (fold)
\label{sec:rich_detector}

Particle identification is a fundamental requirement for many analyses at the LHC\textit{b} experiment. LHC\textit{b} is 
unique at the LHC in the sense that it uses RICH detectors for hadronic particle identification, unlike other LHC experiments such as ATLAS or CMS. The advantage of using RICH detector is that it yields superior particle identification performance. Using three different radiators, the RICH detectors cover a wide range of momentum (1-100 $\text{GeV}/c$).

Both RICH-1 and RICH-2 are located in low magnetic field regions to keep the trajectories of charged particles straight while they pass through the radiators. They both also have tilted spherical focusing primary mirrors and secondary flat mirrors to limit the length of the detector along the beam pipe and minimize the amount of detector material. The spherical focusing mirrors use the property that photons generated at a fixed angle with respect to the particle trajectory are focused onto a ring in the photon detector plane (via the secondary flat mirror) where hybrid photon detectors (HPD) are used to measure the spatial position of emitted Cherenkov photons. These photon detectors have a spatial resolution of 2.5\,mm $\times$ 2.5\,mm. The total area of the two detector planes in the RICH-1 detector is $1302$\,mm $\times 555$\,mm each and $710$\,mm $\times 1477$\,mm for RICH-2.  The HPD is a vacuum photon detector in which a photoelectron, released from the conversion in a photocathode of an incident photon, is accelerated by and applied voltage onto a silicon detector \cite{AlvesJr2008}. 

The RICH-1 in front of the magnet covers the lower momentum range from 1-60 $\text{GeV}/c$. It uses two radiators 5\,cm thick aerogel tiles with $n=1.03$ which is suited for the lowest momentum tracks and directly behind about 1\,m of $\text{C}_4\text{F}_{10}$ ($n=1.0014$) which covers the intermediate region of momentum. For the highest momentum tracks, 
gaseous $\text{C}\text{F}_4$ ($n=1.0005$) is used in the RICH-2 \cite{LHCb2000}.

There is a strong correlation between the polar angle and the momentum of the charged particles produced in LHC\textit{b}. Particles with a larger polar angle tend to have lower momentum. This is why RICH-1 with the aerogel is located before the dipole magnet so tracks with low momentum will be covered before they are swept out of the acceptance by the magnet. See Figure~\ref{fig:rich1} for a schematic of the RICH-1 detector.

\begin{figure}[tb]
  \centering
  \includegraphics[width=0.5\textwidth]{pics/rich1-2d}
  \caption{RICH-1 detector \cite{LHCb:2000}}
  \label{fig:rich1}
\end{figure}


% section rich_detector (end)


% section cherenkov_radiation (end)

\section{Hough transform} % (fold)
\label{sec:hough_transform}

The Hough transform \cite{Duda:1972} is a feature extraction technique used in image analysis, computer vision and digital image processing.

Its purpose is to find imperfect instances of objects within a certain class of shapes by a voting procedure. This voting procedure is 
carried out in a parameter space from which object candidates are obtained as local maxima in a so called accumlator space that is 
explicitly constructed by the algorithm for computing the Hough transform.

Initially the Hough transform was concerned with finding straight lines \cite{c1962method} but it has been extended to identifying positions 
of more complicated shapes, such as circles and ellipses.

\subsection{Linear Hough transform} % (fold)
\label{sub:linear_hough_transform}

A linear function is often parametrized as:

\[
  f(x) = m\cdot x + b
\]
where $m$ is the slope of the line and $b$ the intercept. For the Hough transform, however, this representation is not ideal. For a 
vertical line, $m$ would go to infinity which gives an unbound parameter space for $m$. For this reason, Duda and Hart suggested the 
$r\text{-}\theta$ parametrization \parencite{Duda:1972}.

\begin{equation}
  r = x\cos\theta + y\sin\theta\label{eq:param_eq}
\end{equation}

where $r$ is the distance from the origin to the closest point on the line and $\theta$ is the angle between the $x$-axis and the line 
connecting the origin with that closest point.

\begin{figure}[ht]
  \centering
  \begin{tikzpicture}[scale=3]
    \draw[<->] (0,1.5) -- (0,0) -- (1.5,0);
    \node [left] at (0,1.5) {$y$};
    \node [below] at (1.5,0) {$x$};
    \draw[magenta,semithick] (0,1) -- (1,0);
    \draw[-> ,semithick] (0,0) -- (0.5, 0.5);
    \draw[semithick] (0.2,0) arc (0:45:0.2cm);
    \node[below] at (0.1,0.121) {\footnotesize$\theta$};
    \node[above] at (0.2,0.2) {$r$};
  \end{tikzpicture}
  \caption{$r\text{-}\theta$ parametrisation}
  \label{fig:rhotheta}
\end{figure}
% subsection linear_hough_transform (end)

This means given a single point in the ($x,y$) plane, the set of all lines going through this point form a sinusoidal curve in 
$r\text{-}\theta$ space. Another point that lies on the same straight line in the ($x,y$) plane will produce a sinusoidal curve that 
intersects with the other at ($r\text{-}\theta$) and so do all the points lying on the same straight line. 


\begin{figure}[tb]
  \centering
  \includegraphics[width=0.8\textwidth]{sim_pics/line_ht_paramspace}
  \caption[Example of a linear HT space]{This is the accumulator space of 3 points on the same line. Each curve represents the set of possible lines going through one particular point. The curve then represents the $r-\theta$ parameters for each line of this set. Since there are three points there are three curves.}
  \label{fig:line_ht}
\end{figure}

\begin{figure}[tb]
  \centering
  \includegraphics[width=0.8\textwidth]{sim_pics/line_ht_paramspace_nomatch}
  \caption[Example of a linear HT where points do not lie on a line]{Example of a linear Hough transform where points do not lie on a line. Since any 
  two points can form a line there are still intersections but never more than 2.}
  \label{fig:line_ht_nomatch}
\end{figure}

\subsection{Circle Hough transform} % (fold)
\label{sub:circle_hough_transform}

For this thesis we are interested in circle detection so we need to adapt the linear Hough transform in order to find circles. 
In a two dimensional space ($x,y$), a circle can be described by:

\begin{equation}
		(x-c_x)^2 + (y-c_y)^2 = r^2
\end{equation}

Where $(c_x,c_y)$ are the coordinates of the center of the circle and $r$ is its radius. The possible parameters for the parameters space are now $c_x, c_y$ and $r$. This means if the center of the circle is known the parameter space is one-dimensional, if the radius of the circle is known the parameter space is two-dimensional and of course if nothing is known the parameter space is three-dimensional.



% subsection circle_hough_transform (end)
% section hough_transform (end)

\section{Datasets} % (fold)
\label{sec:dataset}
Two Monte-Carlo generated sets of simulated data were used for this thesis. The algorithms were trained on a data set of 250 simulated events and the performance of the algorithms was tested on a data set consisting of 10'000 simulated events with a total of 49'979 rings across all events. The properties of these events (radiuses, number of points per ring, number of rings per event) are taken from both simulation of LHC\textit{b} events and
real data taken from the experiment. The number of points per ring is determined by the photoelecton yield N$_\text{pe}$ which is shown in Table~\ref{tab:results}. Figure~\ref{fig:ppc1} shows the number of points per circle and Figure~\ref{fig:circlePerEventDist} the number of circles per event for the test data set.

\begin{table}[tb]
\centering
\begin{tabular}{c c c}
\toprule
\multirow{2}{*}{Radiator} & \multicolumn{2}{c}{Average N$_{\text{pe}}$ from data} \\
\cmidrule{2-3} &  tagged D$^0 \rightarrow$ K$^- \pi^+$ &pp$ \rightarrow$ pp $\mu^+ \mu^-$ \\
\midrule
Aerogel & $5.0 \pm 3.0$  & $4.3 \pm 0.9$\\
C$_4$F$_{10}$  & $20.4 \pm 0.1$ & $24.5 \pm 0.3$ \\
CF$_4$ & $ 15.8 \pm 0.1$  & $ 17.6 \pm 0.2$ \\ 
\bottomrule
\end{tabular}
\caption[Comparison of photoelectron yields (N$_{\rm pe}$)]{Comparison of photoelectron yields (N$_{\rm pe}$) determined from
D$^* \rightarrow$D$^0\pi^+$ decays and pp $\rightarrow$ pp $\mu^+ \mu^-$ events in data, using the selections and 
methods described in the text \cite{RICHPerf2012}}
\label{tab:results}
\end{table}

\begin{figure}[tb]
  \centering
  \includegraphics[width=0.6\textwidth]{sim_pics/ppc}
  \caption{Number of points per circle (N$_\text{pe}$) for the 10'000 simulated events in the test data sample}
  \label{fig:ppc1}
\end{figure}

\begin{figure}[tb]
  \centering
  \includegraphics[width=0.6\textwidth]{sim_pics/circlePerEventDistribution}
  \caption{Number of circles per event in the test data sample}
  \label{fig:circlePerEventDist}
\end{figure}

The average radius of Cherenkov rings can be found in \cite{Forty1999}. Rings from the C$_4$F$_{10}$ radiator in RICH-1 have radiuses generally smaller than $0.15$\,m. Rings from the aerogel have slightly bigger radiuses of around $0.20$\,m). All generated rings in the test data set have a radius that is smaller than $0.15$\,m. The distribution of the radiuses in the test data set is shown in Figure~\ref{fig:radius_dist}.

\begin{figure}[tb]
  \centering
  \includegraphics[width=0.6\textwidth]{sim_pics/radiusDist}
  \caption{Distribution of ring radiuses in the test data sample}
  \label{fig:radius_dist}
\end{figure}
% section dataset (end)

\section{Existing algorithm} % (fold)
\label{sub:existing_algorithm}
There is already an algorithm in place in LHC\textit{b} \cite{Forty1999}. The disadvantage of the existing algorithm is due to the 
fact that it uses tracks to reconstruct the circles. All charged tracks that are reconstructed by the tracking system are reflected at
the RICH mirrors in order to define a center for a potential Cherenkov ring.

% subsection existing_algorithm (end)

\chapter{Methods}

\section{Conventional Hough transforms} % (fold)
\label{sec:conventional_hough_transforms}

In the following subsections we discuss  conventional Hough transforms for the cases of a one, two and three dimensional parameter space (known center, known radius, unkonwn radius and center). 
These methods were mainly considered to get an idea of what was possible with the conventional Hough transform.
The conventional Hough transforms use the accumulator space which is essentially a histogram. As such it depends on the size of the binning. The finer the binning is the higher the accuracy with which parameter ($r$ and/or ($x,y$) coordinate) can be extracted. On the other hand the execution time depends on the binning; the finer the binning the longer the execution time.

For closer study the 
method of choice was the combinatorial triplet Hough transform discussed in section \ref{sec:combinatorial_approach}.
% section conventional_hough_transforms (end)

\subsection{1D: Known center - find radius} % (fold)
\label{sub:1d_known_center_find_radius}

In this case the centers of all circles are known and the algorithm has to find the radiuses. For the radius, a one dimensional array is defined with a 
minimum value and with a fixed stepsize to the maximum possible radius. For the example studied here, the minimum was chosen to be $0$, 
the maximum radius to be $1$ and the stepsize equal to $0.001$. The following scoring function $\eta(r)$ was used to calculate the distance
of a data point ($x,y$) from the given center ($c_x, c_y$) as a function of the radius $r$:

\begin{equation}
\label{eq:score_function}
  \eta(r) = (c_x - x)^2 + (c_y - y)^2 - r ^ 2.
\end{equation}

For $\eta(r)=0$, the particular point ($x,y$) would lie on the circle of radius $r$ with center ($c_x, c_y$).
A Gaussian distribution 

\begin{equation}
\label{eq:weight_function}
  w(\eta) = \frac{1}{\sqrt{2\pi}\sigma}\exp\left( \frac{-\eta^2}{2\sigma^2}\right),
\end{equation}

is used to have a well defined value for such points. A point ($x,y$) that is not exactly on the circle will still contribute to the total score. The smaller the parameter $\sigma$, the tighter the range is
in which a point will be considered lying on a circle or not.

The value from equation \ref{eq:weight_function} is added to the bin in the radius histogram which corresponds to the value of $r$ used to
calculate the weight.

\begin{figure}[ht]
\centering
  \begin{tikzpicture}
    \begin{axis}[
    axis lines = center,
    ymin=0, ymax=45,
    xlabel = $\eta$,
    scaled x ticks = false,
    % x tick label style={},
    x label style={at={(axis description cs:1.05,0.0)},anchor=north},{/pgf/number format/fixed},
    ylabel = $\omega(\eta)$,
    legend style={at={(0.2,0.7)},anchor=east},
    legend cell align=left,
    ]
    \addplot [
    domain=-0.05:0.05, 
    color=red,
    samples=200,
    ]
    { 1/(sqrt(2*pi)*0.01)*exp(-x^2/(2*0.01^2))};
    \addplot [
    domain=-0.05:0.05, 
    color=blue,
    samples=200,
    ]
    { 1/(sqrt(2*pi)*2*0.01)*exp(-x^2/(2*(2*0.01)^2))};
    \addlegendentry{$\sigma=0.01$}
    \addlegendentry{$\sigma=0.02$}
    \end{axis}

  \end{tikzpicture}
    \caption[Normal Distribution: Used as a weight function]{Using the probability density function of the normal distribution to 
    calculate the score of a point in order to have a well defined maximum if a point lies directly on the circle and $\eta(r) = 0$. 
    Increasing the $\sigma$ increases the width of the function and by extension increases the score of points that do not lie directly on the circle}
  \label{fig:gauss}
\end{figure}
Equation \ref{eq:score_function} is of course just the circle equation with $c_x, c_y$ being the known coordinates of the center of 
the circle, $x, y$ are the data points and $r$ is the radius. If many data points have the same distance $r$ from the circle 
center there will be a high score for this particular radius. The index of the bin with the highest score can then be used to find the 
corresponding radius. The pseudo code for this Hough transform is shown in Code Snippet \ref{pc:1dHT}. An example of a resulting radius
histogram is shown in figure \ref{fig:1d_ht_radius_score}

\begin{codesnippet}[htb]
  \begin{lstlisting}
  DMENSION = 1001
  r= linspace(0,1,DIMENSION)
  for c_x, c_y in centers:
    scores = zeros(DIMENSION)
    for x,y in allPoints:
      s = 2*BIN_WIDTH
      eta = (c_x-x)**2 + (c_y-y)**2 - r**2
      scores += 1. / ( sqrt( 2 * Pi ) * s ) 
                 * exp( -( eta ** 2 ) 
                  / ( 2 * s ** 2 ) )
    index = max(scores)
    circle = {}
    circle['center'] = c
    circle['radius'] = r[index]
\end{lstlisting}
\caption[Pseudo Code 1D HT]{Pseudo code for the 1D Hough transform. r is an array of length 1001 so $\eta$ will also be an 
array of length 1001. Scores is the array in which the score for each iteration is stored. For each point the score is computed and added 
to the scores array and at the end the index with the highest score is the index we need to extract the radius}\label{pc:1dHT}
\end{codesnippet}

\begin{figure}[tb]
  \centering
  \includegraphics[width=0.8\textwidth]{sim_pics/1D_HT/radius_scores_5_circles_30_bg_1}
  \caption[Graph visualisation of a 1D radius histogram]{Visualisation of a 1D radius score histogram. The peak between $0.2$ 
  and $0.3$ has by far the highest score and the bin
  position of the peak is the radius candidate for a given circle center ($c_x, c_y$)}
  \label{fig:1d_ht_radius_score}
\end{figure}

\subsubsection{Complexity} % (fold)
The complexity of this algorithm is of $\mathcal{O}(n)$ where $n$ is the number of bins in the radius histogram.
\label{ssub:complexity_1d}

% subsubsection complexity (end)

% subsection 1d_known_center_find_radius (end)
\subsection{2D: Known radius - find center} % (fold)
\label{sub:2d_known_radius_find_center}
In this case the radius is known and the $x$ and $y$ coordinates of the center $(c_x, c_y)$ are unknown. The accumulator is two 
dimensional. The range of that space is the dimension of the detection plane which for this thesis is set to $[-0.5,0.5]$. The size of the 
bins is chosen to be 0.001 since the known radiuses given from the test data were given with this precision. If the detection plane was in 
reality 1\,m by 1\,m (approximately the dimension of the RICH detectors) the binning of the accumulator in each dimension is 1 mm which is
better than the resolution of the HPDs ($2.5$\,mm $\times$ $2.5$\,mm) . As in the one dimensional case we use the scoring function 
\ref{eq:score_function} in combination with the weight function \ref{eq:weight_function}.
Since it is likely that two rings have very similar radiuses within the precision of the binning a mechanism has to be introduced to
remove points from the data set that have been used for a ring. For two circles with the same radius the algorithm would only ever find 
the one with the higher score. To avoid this once a circle has been found a check for each data point is made to see whether or not it 
lies on the circle and if yes it is removed (see Code Snippet~\ref{lst:remove_points}).

\begin{codesnippet}[htb]
\begin{lstlisting}
  DIMENSION = 1001
  xbins = linspace(-0.5,0.5,DIMENSION)
  ybins = linspace(-0.5,0.5,DIMENSION)
  x, y = broadcast_arrays( xbins[..., newaxis], 
                           ybins[newaxis,...] )

  for r in Radiuses:
    weights = zeros( (DIMENSION,DIMENSION) )
    for xd,yd in allPoints:
      s = 2*BIN_WIDTH
      eta = (xd-x)**2 + (yd-y)**2 - r**2      
      weights += 1. / ( sqrt( 2 * pi ) * s ) 
                 * exp( -( eta ** 2 ) 
                 / ( 2 * s ** 2 ) )
    i, j = argmax(weights)
    removeUsedPoints()
    circle['Center'] = (xbins[i], ybins[j])
    circle['Radius'] = r
\end{lstlisting}
  \caption[Pseudo code 2D HT]{Pseudo code for the 2D Hough transform. \texttt{xbins} and \texttt{ybins} are one-dimensional arrays of length 1001. Here we use array 
  broadcasting in order to avoid for loops and the weights can be evaluated in one line.}
\end{codesnippet}


\begin{codesnippet}
\begin{lstlisting}
    for x,y in data_points:
    if ( x - c_x )**2 + ( y - c_y )**2 - r**2 < 0.002:
      <delete x,y from the list>
\end{lstlisting}
\caption[Removing data points that lie on a ring]{Pseudo code for removing data points that lie on a ring. The value of $0.002$ is twice the bin size to make sure all the points that
belong to that ring will be removed. ($c_x, c_y$) is the center found by the algorithm and $r$ is given from the data.}\label{lst:remove_points}
\end{codesnippet}

\subsubsection{Complexity} % (fold)
\label{ssub:complexity_2d}
The complexity of this algorithm is $\mathcal{O}(n\times m)$ where $n$ and $m$ are the number of bins per coordinate respectively of 
the histogram. The calculation of the weight has to be done for each data point of the 2D histogram. So in a $1000\times 1000$ histogram 
with 400 data points we calculate 400'000'000 times the weight of a grid point. Reducing the dimensions of the histogram weakens the 
accuracy of the algorithm but can speed up the calculations considerably. With a $1000\times 1000$ histogram the resolution in each 
space dimension is $1$\,mm. The RICH Technical Design Report states the resolution of the HPD is $2.5$\,mm $\times$ $2.5$\,mm.

The need (not entirely true -- see below) to calculate the weight for each grid point and data point means that there is a loop over all
data points and two loops over the $x$ and $y$ coordinates of the grid. To improve upon that there is the possibility of array broadcasting.
% subsubsection complexity (end)

\newpage
\subsubsection{Array broadcasting}
Consider following one dimensional arrays where both $x$ and $y$ are a 1D histograms binning entries from 1 to 4: 
\begin{align*}
  x &= [1, 2, 3, 4]\\
  y &= [1, 2, 3, 4]  
\end{align*}
All combinations between an element of $x$ and and element of $y$ represent a 2D grid $\left((1,1), (1,2), ...\right)$. To iterate through 
all those grid points one would have to create 2 for-loops iterating through $x$ and $y$ as shown in this pseudo code snippet: %\ref{pc:nested_loops}.
% \begin{figure}[tb]
    \begin{lstlisting}
  def noBroadcast():
  a = np.random.randn(100)
  b = np.random.randn(100) 
  for x in a:
    for y in b:
      print (1-x)^2 + (2-y)^2 - 9
\end{lstlisting} 
% \caption[2 for-loops example]{To calculate the statement for every value in $a$ and $b$ the program has to do nested for-loops}\label{pc:nested_loops}
% \end{figure}

This is not only slow but also does not look nice if there are even more loops (readability of the code).
Broadcasting turns the one dimensional arrays of length $n$ into two $n\text{ by }n$ matrices
\[
  x = \begin{bmatrix}
  1 & 1 & 1 & 1 \\
  2 & 2 & 2 & 2 \\
  3 & 3 & 3 & 3\\
  4 & 4 & 4 & 4
  \end{bmatrix}
\]
and
\[
  y = \begin{bmatrix}
  1 & 2 & 3 & 4 \\
  1 & 2 & 3 & 4 \\
  1 & 2 & 3 & 4 \\
  1 & 2 & 3 & 4 
\end{bmatrix}
\]
\noindent\begin{minipage}{\linewidth}
And with this the loops can be omitted as shown in the following example,
\begin{lstlisting}
def withBroadcast():
  a = np.random.randn(100)
  b = np.random.randn(100) 
  x,y = np.broadcast_arrays(a[...,np.newaxis],
                            b[np.newaxis,...])
  print (1-x)^2 + (2-y)^2 - 9
\end{lstlisting}  
\end{minipage}
which prints a $4$ by $4$ array with the function evaluated for each combination of entries of $x$ and $y$
\[
  \begin{bmatrix}
    -8& -9& -8& -5\\
    -7& -8& -7& -4\\
    -4& -5& -4& -1\\
     1&  0&  1&  4
       \end{bmatrix}
\]
%
\begin{minipage}{\linewidth}
A runtime comparison shows   
\begin{lstlisting}
In [3]: %timeit withBroadcast()
10000 loops, best of 3: 76.8 us per loop

In [4]: %timeit noBroadcast()
100 loops, best of 3: 7.99 ms per loop
\end{lstlisting}
The version with broadcasting is 100 times faster than the double loop. And the memory consumption is moderate since the 
broadcasted entries are not new memory locations but just refer to the initial array.
\end{minipage}


\subsubsection{Optimizations} % (fold)
\label{ssub:optimizations}
It was claimed before that for each data point the weight for the whole grid has to be calculated. This is in fact not true. In the 2D case 
each grid point is a potential center for a circle only if it is not further away from a data point than the maximum ring radius $R_T$, 
so if a grid point is further away than $R_T$ this calculation could be skipped. This could probably be done even smarter with the use of a 
sub grid so only points in the surrounding sub grids are considered of being possible centers rather than the whole grid.

% subsubsection optimizations (end)

\subsubsection{Simple example: 2 circles without background} % (fold)
\label{ssub:simple_example_of_2_circles_without_background}
\begin{figure}[hp]
  \centering
  \begin{tikzpicture}
    \node[anchor=south west,inner sep=0] (image) at (0,0) {\includegraphics[width=0.5\linewidth]{sim_pics/2D_HT/center_scores_2_circles_0_bg_1_properlabels.png}};
    % \begin{scope}[x={(image.south east)},y={(image.north west)}]
    %       \draw[white,thick,->] (0.62,0.4) -- (0.56,0.31);
    % \end{scope}
  \end{tikzpicture}%
  \begin{tikzpicture}
    \node[anchor=south west,inner sep=0] (image) at (0,0) {\includegraphics[width=0.5\linewidth]{sim_pics/2D_HT/center_scores_2_circles_0_bg_2_properlabels.png}};
    % \begin{scope}[x={(image.south east)},y={(image.north west)}]
    %       \draw[white,thick,->] (0.6,0.5) -- (0.68,0.555);
    % \end{scope}
  \end{tikzpicture}
  

  \caption[2D weight matrix, first iteration]{(Left) 2D weight matrix in the first iteration of the Hough transform algorithm. (Right) Second iteration
  of the 2D weight matrix of the Hough transform. Data points that satisfied the condition of being less than a certain distance $\epsilon$ 
  away from the circle found in the first iteration are removed, leaving (hopefully) only data points available that belong to the second ring}
  \label{fig:2d_weights_01}
\end{figure}
% subsubsection simple_example_of_2_circles_without_noise (end)
% section 2d_known_radius_find_center (end)

\subsection{3D: All parameters unknown} % (fold)
\label{sub:3d_nothing_is_known_find_everything}
In this case all that is known are the data points and the algorithm has to retrieve both the centers and the radiuses of all rings.
Moreover, the total number of rings is not necessarily known. The accumulator space is now three dimensional, two for the coordinates of the center and one for the radius. Similar to the 2D case, 
array broadcasting (see code snippet~\ref{pc:3D_broadcasting}) is used to speed up the calculations of the weights. Furthermore, 
the algorithm has to decide itself whether or not  all circles have been found a condition has to be set to decide when there are no more circles.

For deciding whether or not the algorithm has found all rings, a simple score threshold is used that whenever the highest score
of the weight matrix is less than this threshold, the algorithm stops and it is assumed that all circles have been found. The threshold
used in this thesis has been determined by trial and error and was set to a score of $3500$. The pseudo code for calculating the weights 
and the threshold check is shown in \ref{pc:3D_threshold}. As in the 2D Hough transform, the algorithm has to remove data 
points that have contributed to the highest score. If this is not done, the algorithm will loop endlessly because always the same score will be 
found. Once the highest score has been found, the center coordinates and radius are extracted from the histogram and the 
algorithm calculates for every data point, if a data point lies on the circle given the extracted center and radius. If the data point 
lies within the distance oftwo times the bin width from the circle, it will be removed (see Code Snippet~\ref{pc:remove_points}).

\begin{codesnippet}[htbp]
  \begin{lstlisting}
xbins = np.linspace(-0.5,0.5,DIMENSION)
ybins = np.linspace(-0.5,0.5,DIMENSION)
rbins = np.linspace(0,0.5, R_DIMENSION)

x,y,r = np.broadcast_arrays(\
            xbins[np.newaxis,...,np.newaxis],\
            ybins[np.newaxis,np.newaxis,...],\
            rbins[...,np.newaxis,np.newaxis])
\end{lstlisting}
\caption[3D broadcasting]{Broadcasting of the 3 arrays $x,y,r$. With this 3 for-loops can be avoided improving speed and readability
of the code.}
\label{pc:3D_broadcasting}
\end{codesnippet}

\begin{codesnippet}[htbp]
  \begin{lstlisting}
while True:
  weights = np.zeros(\
         (R_DIMENSION, DIMENSION, DIMENSION))

  for x0,y0 in data['allPoints']:
    s = 0.001
    eta = (x-x0)**2 + (y-y0)**2 - r**2
    weights += 1./( sqrt( 2 * sconst.pi ) * s )*\
                      np.exp( -( eta ** 2 ) / \
                      ( 2 * s ** 2 ) )
  index = np.argmax( weights )
  rr,ii,jj = np.unravel_index( index, 
              (R_DIMENSION, DIMENSION, DIMENSION))
  score = weights[rr][ii][jj]
  if score < THRESHOLD:
    break  
\end{lstlisting}
\caption[Calculation of weights and threshold check for 3D HT]{The while loop works as long as the highest found score is higher than
\texttt{THRESHOLD}. If the score is lower than the threshold the loop breaks and the function returns the results that have been found.}
\label{pc:3D_threshold}
\end{codesnippet}

The same scoring function as before is used, but this time it is a function of all three parameters $\eta(x,y,r)$:
\begin{equation}
  \eta(x,y,r) = (x - d_x)^2 + (y - d_y)^2 - r ^ 2
\end{equation}
where $d_x$ and $d_y$ are the coordinates of  data points. Again, 
\begin{equation}
  w(\eta) = \frac{1}{\sqrt{2\pi}\sigma}\exp\left( \frac{-\eta^2}{2\sigma^2}\right).
\end{equation}

\begin{codesnippet}[htbp]
\begin{lstlisting}
circle['center'] = (xbins[ii], ybins[jj])
circle['radius'] = rbins[rr]
circles.append(circle)

used_xy += [tup for tup in data['allPoints'] if
    abs( ( tup[0] - circle['center'][0] ) ** 2 +
         ( tup[1] - circle['center'][1] ) ** 2 -
         circle['radius'] ** 2 ) < 2 * 0.001]
data['allPoints'][:] = 
            [tup for tup in data['allPoints'] if 
    abs( ( tup[0] - circle['center'][0] ) ** 2 + 
         ( tup[1] - circle['center'][1] ) ** 2 - 
         circle['radius'] ** 2 ) >= 2 * 0.001]  
\end{lstlisting}
\caption[Remove used points]{In order to avoid finding the same ring over and over again, the algorithm has to remove points that
belong to a found ring. If a data point lies within two times the bin width from a circle the algorithm considers that data point to be 
part of the corresponding ring and removes that data point from the list.}
\label{pc:remove_points}
\end{codesnippet}

\subsubsection{Complexity} % (fold)
\label{ssub:complexity}
The complexity of this algorithm is of order $\mathcal{O}(m\times n\times u)$. As in the case of the 1D and 2D Hough transform, the accuracy
depends on the binning. For the 3D Hough transform to match the resolution of the HPD of the LHC\textit{b} RICH detector a binning 
of 400 bins in each of the two center coordinate parameters makes sense if the detector dimensions are $1$\,m$\times1$\,m.
% subsubsection complexity (end)

\subsubsection{Optimisations} % (fold)
\label{ssub:optimisations}
As for the 2D HT introducing a sub grid can be introduced for the $x,y$ plane so only grid points within a predefined distance of a 
data point are used for calculating the score.
% subsubsection optimisations (end)
% subsection 3d_nothing_is_known_find_everything (end)

\section{Combinatorial triplet Hough transform}
\label{sec:combinatorial_approach}
A circle is uniquely defined by 3 points and its radius and the coordinates of its center can be calculated from the coordinates of these points. If there are 
15 points lying on the same circle there are 455 possible combinations of triplets according to the binomial distribution,
\[
   \binom{N}{3} = \left(\frac{N!}{k!(N-k)!}\right).
 \]
Calculating the center and radius for these 455 triplets should result in the same center ($x,y$) and same radius $r$ for all the triplets 
(effects of detector resolution and floating point inaccuracy not considered). 

Having one random background hit in addition to the 15 points on the circle increases the number of triplets to 560. The triplets 
solely consisting of points on the circle still yield the same center and radius but the combinations that include a background hit will 
give different results and it is unlikely that two triplets that include the background point will yield the same center and radius. 
Here is an overview of the algorithm studied in this thesis.

\begin{enumerate}
\item Build all possible triplets of the data points.
\item For all triplets calculate the center and the radius of the potential circle.
\item Remove all triplets that yield a radius bigger than a pre-defined threshold.
\item Create a histogram with the distribution of $r$ for the remaining triplets. Peaks in this histogram hint at the presence of a circle.
\item Scan the radius histogram for peaks and look at the 2D histogram of ($x,y$) for all triplets that belong to a given peak in the 
$r$ distribution. If there is also a peak in the ($x,y$) histogram, the set of the points forming the triplets lie on a circle with a 
radius and center given by the positions of the peaks in the $r$ and ($x,y$) histograms.
\end{enumerate}

\subsection{Generating the triplets} % (fold)
\label{sub:generating_the_triples}
To generate the triplets, the python function \texttt{itertools.combinations()} from the \texttt{itertools} module is used. The input 
for this function is an iterable, in our case a list of tuples (each tuple containing the $x$ and $y$ coordinate of a data point) which is 
used to create all possible combinations of triplets (of said tuples).

% subsection generating_the_triples (end)

\subsection{Calculating the Circle given 3 points}

Let $(A,B,C)$ be a triplet of points in a 2D plane and $a,b,c$ the lengths of the sides opposite to the respective corner.
%
The semiperimeter is defined as
%
\begin{equation}
  s = \frac{a+b+c}{2}.
\end{equation}
%
The radius $R$ of the circumcircle of the triangle $\overline{ABC}$ is:
\begin{equation}
  R = \frac{abc}{4\sqrt{s(a+b-s)(a+c-s)(b+c-s)}}
\end{equation}
and the barycenteric coordinates of the circumcenter are:
\begin{align}
  \lambda_1 &= a^2\cdot(b^2+c^2-a^2)\\
  \lambda_2 &= b^2\cdot(a^2+c^2-b^2)\\
  \lambda_3 &= c^2\cdot(a^2+b^2-c^2)
\end{align}
Multiplying a matrix consisting of the column vectors of $A,B,C$ ($A_x,A_y$; $B_x,B_y$; $C_x,C_y$) with a column vector of $\lambda_1, \lambda_2, \lambda_3$ and dividing the resulting vector by the sum of the barycentric coordinates (for normalization) yields the coordinate of the circumcenter of the triangle $\overline{ABC}$ 
%
\begin{equation}
  \begin{pmatrix}
    A_x & B_x & C_x \\
    A_y & B_y & C_y
  \end{pmatrix} \cdot \begin{pmatrix}
    \lambda_1\\
    \lambda_2\\
    \lambda_3
  \end{pmatrix} = \begin{pmatrix}
    P_x'\\
    P_y'
  \end{pmatrix}
\end{equation}
%
\begin{equation}
  \frac{\begin{pmatrix}
    P_x'\\
    P_y'
  \end{pmatrix}}{\lambda_1+\lambda_2+\lambda_3} = \begin{pmatrix}
    P_x\\
    P_y
  \end{pmatrix} = \boldsymbol{P}
\end{equation}
%
\begin{figure}[tb]
\centering
\begin{tikzpicture}
\coordinate (A) at (0,0);
\coordinate (B) at (2.5,0);
\coordinate (C) at (2,3);
\coordinate (Ci) at (1.25,1.33333);
\def\r{1.827}
\draw[thin] (A) -- (B) -- (C) -- cycle;
\node[left] at (A) {$A$};
\node[right] at (B) {$B$};
\node[above] at (C) {$C$};
\node[below] at (0.34,2.3) {$R$};
\draw[fill=black] (A) circle (1pt);
\draw[fill=black] (B) circle (1pt);
\draw[fill=black] (C) circle (1pt);
\draw[fill=red] (Ci) circle (2pt) node [below] (Ci) {$P$};

\draw[->] (1.25,1.33333) -- +(150:1.827);
\draw[red] (1.25,1.33333) circle (1.827);
\end{tikzpicture}
\caption{The circumradius ($R$) and the circumcenter ($P$) of a circle defined by three points ($A,B,C$).}
\label{fig:circum_fig}
\end{figure}



\subsection{Ring finding} % (fold)
\label{sub:finding_the_radius_and_center_of_a_circle}
Once $R$ and $\mathbf{P}$ are calculated these values are stored as a pair in a tuple. A list is formed that holds all tuples ($R, \mathbf{P}$)
for all triplets.

The next step is binning this data for $R$. For each bin in $R$, a list is created which contains the $\mathbf{P}$ information for all
($R,\mathbf{P}$) tuples with $R$ in this bin. This allows the algorithm when looking for a peak in the $R$ histogram to access the values of
$\mathbf{P}$ for this $R$ value. 

\subsubsection{Ring finding threshold} % (fold)
\label{sub:different_thresholds}
The algorithm applies a simple threshold on the number of associated points to decide whether a candidate is a ring or not. Assume just 
one ring with 10 points. From these 10 points, the algorithm creates 120 triplets $\left(\binom{10}{3}\right)$. For each of these triplets,
the radius and the coordinates of the center are calculated. Since all triplets belong to the same ring the radius histogram has one peak at 
the value of the ring radius and the center histogram has one peak at the coordinates of 
the ring center. If the applied threshold is less or equal than 120, this ring will be found. So essentially we can 
decide how many points per ring are needed in order to be recognized as a ring and define the threshold as

\begin{equation}
  \binom{\text{Number of Points}}{3} = \text{Threshold}.
  \label{eq:threshold}
\end{equation}

This threshold is used for the radius and center finding of the algorithm.

\subsubsection{Finding the radius} % (fold)
\label{ssub:finding_the_radius}
Once the radius histogram is filled, the algorithm looks for the index at which the maximum value of the histogram is stored. The algorithm
then checks if the sum of the number of entries at this index and its the and right neighbours exceeds the radius threshold ()which is a tuning parameter). If this is the case, the algorithm creates a list of the ($x,y$) coordinates for all tuples corresponding to this index and its left and right neighbours.

The code for extracting the radiuses with their center data is shown in Code Snippet \ref{pc:radius_extraction}. Assuming bin index $i$ 
contains the highest score of the histogram. The code then adds the score from bin $i-1$ and $i+1$ to the maximum score and checks if 
the sum is bigger than the threshold. If that's the case the next step adds the center information stored in \texttt{center} to a separate
list. The function then returns a list of radiuses that exceed the threshold and for each radius in the list there is a list of center data which is used to 
extract the center of the ring.
\begin{codesnippet}
  \begin{lstlisting}
edges #x edges of the histogram
center #center data
while True:
  i = max(H)
  n = NUMBER_OF_R_BINS 
  n_entries = sum(H[i-1 if i>0 else i:i+2 
                    if i<n-1 else i+1])
  if n_entries < RADIUS_THRESHOLD:
    # there are less than THRESHOLD
    # entries in 3 bins
    break
  radiuses.append(edges[i])
  index_list = range(i-1 if i>0 else i,i+2 
                     if i<n-1 else i+1)
  for index in index_list:
    if center[index]:
      center_list += center[index]
    H[index] = 0
  center_data.append(center_list)    
return radiuses, center_data 
\end{lstlisting}
\caption[Radius extraction algorithm]{This code shows how the radius maxima are found and their respective center data is extracted.
\texttt{n\_entries} is the sum of the score of the maximum bin and its left and right neighbour. If the score exceeds the threshold the entries of these three bins are set to 0 and the radius value together with the center data are returned.}\label{pc:radius_extraction}
\end{codesnippet}

As long as the found maximum is bigger then the threshold the algorithm keeps looking for radiuses.

\subsubsection{Finding the center} % (fold)
\label{ssub:finding_the_center}
Using this list of center coordinates $\mathbf{P}$ of a radius peak the algorithm now looks for a peak in the ($x,y$) plane of the $\mathbf{P}$ histogram. If the sum of the number of entries in the peak and its four directly adjacent bins exceeds the center threshold, the radius and center coordinates are saved as a ring candidate. Code Snippet~\ref{cs:center_extraction} shows the center extraction.
% subsubsection finding_the_center (end)
% subsubsection finding_the_radius (end)
% subsection finding_the_radius_and_center_of_a_circle (end)

\begin{codesnippet}
  \begin{lstlisting}
H #2d histogram with the center data
xedges 
yedges 
centers = []
n = NUMBER_OF_S_BINS
while True:
  i,j  = max(H)
  score =   sum(H[i-1 if i>0 else i:i+2 
                if i<n else i+1,j]) + 
            sum(H[i, j-1 if j>0 else
                j:j+2 if j+2 <= 3 
                else j+1]) - H[i,j]
  if score < CENTER_THRESHOLD:
    break
  i_index = range(i-1 if i>0 
              else i,i+2 if i<n else i+1)
  j_index = range(j-1 if j>0 
              else j,j+2 if j<n else j+1)
  for ii in i_index:
    H[ii][j] = 0  
  for jj in j_index:
    H[i][jj] = 0
  centers.append( {'center' : (xedges[i], yedges[j]), 
                              'nEntries' : score } )

return centers
\end{lstlisting}
\caption[Center coordinate extraction]{H is the center histogram. After finding the index for the maximum value the values of the 
adjacent neighbours are also added to the score. If the score exceeds the center threshold the algorithm stores them as a center for
a circle candidate and sets the used bins to 0.}\label{cs:center_extraction}
\end{codesnippet}


After this step the ring finding algorithm is done. The result for a typical event is shown in Figure~\ref{fig:comb_ht_0009}. A cleaning step is now performed to remove duplicates. The algorithm compares all found circles and if the center coordinates and the radiuses of two circles are within a certain range these circles are considered to be duplicates and the one with the lower score is discarded. The range cuts were parameters that had to be tuned. If the range was too small then some duplicates were not detected. If the cut was too large, true rings were removed because they
happend to be close to another ring. In Tables~\ref{tab:cut_variation_1} and \ref{tab:cut_variation_2} the effects of different
cuts can be seen.


\begin{figure}[htb]
  \centering
  \includegraphics[width=\textwidth]{sim_pics/Comb_HT/0009.pdf}
  \caption{The result of the combinatorial triplet Hough transform before cleaning up duplicates. The blue and purple circles are basically the same ring.}
  \label{fig:comb_ht_0009}
\end{figure}


\subsection{Removing duplicates} % (fold)
\label{ssub:getting_rid_of_duplicates}

The the main parameters for removing duplicates are used to decide whether a circle is a duplicate or not:
\begin{itemize}
  \item Distance between centers of pairs of rings
  \item Difference between radiuses of pairs of rings
\end{itemize}

% subsection overview_of_the_results (end)


% subsubsection getting_rid_of_duplicates (end)

Without cleaning up the algorithm finds a lot of duplicates. The reason for such duplicates can be background hits or a hits from another 
ring close to the actual ring. The triplets including one of these hits can shift the center or the radius of the ring
they form just a little bit away from the true ring. As shown in Figure~\ref{fig:2bins_highscore} indicated with an arrow there are peaks seperated by one bin and thus the algorithm finds these peaks seperately since only the directly adjacent neighbours are considered. It is possible that there are two
rings with very similar radius but more often it is the same ring in addition with a background hit that lies close to the ring.

\begin{figure}[htb]
  \centering
  \begin{tikzpicture}
    \node[anchor=south west,inner sep=0] (image) at (0,0) { \includegraphics[width=\textwidth]{sim_pics/radius_histogram_0009}};
    \begin{scope}[x={(image.south east)},y={(image.north west)}]
          \draw[black,thick,->] (0.7165,0.5) -- (0.7165,0.425);
          \draw[black,thick,->] (0.7258,0.41) -- (0.7258,0.335);
          \draw[black,thick,->] (0.7360,0.485) -- (0.7360,0.410); 
    \end{scope}
  \end{tikzpicture}
 
  \caption[Histogram of duplicates]{Two almost adjacent bins with a high score\label{fig:2bins_highscore}. Apart from the very clear peak of two bins next to each
  other at $r \approx 0.125$ with a score of 7000 and 6000 respectively, there are 3 smaller peaks separated around $r \approx 0.11--0.12$.
  The highest score is clearly visible. After the algorithm found this maximum and sets the bins to 0 the algorithm picks then the next
  maximas and its neighbours. But since there are several peaks separated by one bin means they are treated seperately and this introduces
  a duplicate.}
\end{figure}

To decide whether or not a circle is a duplicate it is compared to all other found candidates and the distance of their centers and difference of their radiuses is compared.

\begin{equation}
\begin{aligned}
\left|\mathbf{c_1}-\mathbf{c_2}\right| &< \text{\texttt{DUPLICATE\_MAX\_CENTER\_DISTANCE}}\\
\left|r_1 - r_2\right| &< \text{\texttt{DUPLICATE\_MAX\_RADIUS\_DISTANCE}}
\end{aligned}
\label{eq:cut1}
\end{equation}

where $c_1$ and $c_2$ are the center coordinates and $r_1$ and $r_2$ the radiuses of the circles.

However if there is no other circle within the threshold distances the circle is unique and will be added to a result list which 
at the end will be returned with all unique circles. 

If the cut is too loose, there is a chance that a true ring gets discarded as a duplicate if its center and radius happens to be close to those of another ring.

\begin{codesnippet}[htb]
\centering
  \begin{lstlisting}
res = []
sorted_results = sorted( results, key=lambda k: 
                  k['nEntries'], reverse=True)
while len(sorted_results):
  circle = sorted_results.pop()
  unique = True
  for dic in sorted_results:
    if (np.linalg.norm(np.array(circle['center']) - 
        np.array(dic['center']))) < 
                    DUPLICATE_MAC_xENTER_DISTANCE and\
       (abs(circle['radius'] - dic['radius']) < 
                    DUPLICATE_MAX_RADIUS_DISTANCE):
      unique = False
      break
  if unique:
    res.append(circle)
return res
\end{lstlisting}
\caption[Pseudo code for removing possible duplicates]{Pseudo code for removing possible duplicates from the circles found by the algorithm. First results are sorted by their number of entries
in the histogram so the least relevant comes first. If for a given circle another circle exists with the same center and radius (within the cuts)
then the circle is considered a duplicate and will be removed. \texttt{DUPLICATE\_MAX\_CENTER\_DISTANCE} and \texttt{DUPLICATE\_MAX\_RADIUS\_DISTANCE} are 
parameters that can be tuned}\label{pc:dup_code}
\end{codesnippet}



\subsection{Combinatorics}
	

The main drawback of this method is that the combinatorics increase with the number $N$ of data points as \( \binom{N}{3} \). 
For example, for 200 data points the number of triplets is

\[ \binom{200}{3} = 1'313'400 \]
and for 300 data points it is
\[ \binom{300}{3} = 4'455'100. \]

The execution time of the algorithm is roughly of the order of $\mathcal{O}(N^3)$ which can be easily seen when taking the upper bound of $\binom{N}{3} \leq \frac{N^3}{3!}$ (see figure \ref{fig:binom_growth}). 
\begin{figure}[ht]
\centering
  \begin{tikzpicture}
    \begin{axis}[
    axis lines = left,
    xlabel = Number of Data Points,
    ylabel = {Number of Combinations},
    legend style={at={(0.3,0.2)},anchor=east},
    ]
    \addplot [
    domain=1:500, 
    color=red,
    ]
    { factorial(x)/(factorial(x-3)*factorial(3))};
    \addplot [
    domain=1:500, 
    color=blue,
    ]
    { x^3/factorial(3)};
    \addlegendentry{$\binom{N}{3}$}
    \addlegendentry{$\frac{N^3}{3!}$}
    \end{axis}

  \end{tikzpicture}
    \caption[Complexity of the combinatorial triplet Hough transform]{Scaling of the algorithm. Binomial growth $\binom{N}{3}$ compared with the approximation $\frac{N^3}{3!}$, where $N$ is the number of data points.}
  \label{fig:binom_growth}
\end{figure}


\subsubsection{Optimisation} % (fold)
\label{ssub:improvement_of_speed}

The algorithm needs a threshold on the minimum height of the peak in the ($x,y$) and $r$ histograms in order to decide if a candidate is a circle or not. The threshold is defined as the binomial coefficient $\binom{T}{3}$. If a ring has $T$ points then there are $\binom{T}{3}$ possible triplets and the circle will be considered as a candidate. If a ring has less than T points then it will never be consiered as a candidate. 

In fact, not only processing the number of triplets created is a speed bump for the execution time but the time it takes to create the triplets scales with $\frac{N^3}{3!}$ as well. Reducing the number of triplets created will speed up the algorithm considerably.

This leads to the idea of splitting the original data set randomly into two lists. For each of these lists, all possible combinations 
of triplets are  created separately and the two lists of triplets are then merged in one single list for further processing. In Figure~\ref{fig:binom_half_growth} 
the difference in combinatorics between $\binom{N}{3}$ and $2\cdot\binom{\frac{N}{2}}{3}$ can be seen.

\begin{figure}[b]
\centering
  \begin{tikzpicture}
    \begin{axis} [
      axis lines = left,
      xlabel = Number of Data Points,
      ylabel = {Number of Combinations},
      legend style={at={(0.3,0.2)},anchor=east},
    ]
    \addplot [
    domain=1:500, 
    color=red,
    ]
    { factorial(x)/(factorial(x-3)*factorial(3))};
    \addplot [
    domain=1:500, 
    color=blue,
    ]
    { 2*factorial(x/2)/(factorial(x/2-3)*factorial(3)) };
        \addlegendentry{$\binom{N}{3}$}
    \addlegendentry{$2\binom{N/2}{3}$}
    \end{axis}
  \end{tikzpicture}
  \caption{Number of combinations with $\binom{N}{3}$ compared to the number of combinations generated from $\binom{N/2}{3}$}
  \label{fig:binom_half_growth}
\end{figure}

The problem with this approach is the possible loss of efficiency, since the
algorithm uses thresholds that define how many entries a bin in the ($x,y$) and the $r$ histograms must 
have in order to be accepted as a candidate circle.
These thresholds should be high enough such that triplets that contain noise points do not contribute significantly to the circle candidates but low enough that real circles with a
low number of points can still be found.

For now we assume that we require a ring to have 10 hits which seems reasonable when looking at Figure~\ref{fig:ppc1} and considering the low probability that 10 random points form a circle. The question is what is probability of splitting points that belong to a specific circle in such way that at least one list yields enough triplets to reach these thresholds.

In Figure~\ref{fig:ratios} it can be seen that even if we split the lists there is a more 
than 50\% chance that we lose no information for rings that have at least 13 points.
\begin{figure}[htb]
  \centering
  \includegraphics[width=\textwidth]{sim_pics/ratio.pdf}
  \caption{The probability when splitting randomly a list of $N$ points into two that one of the two sublists contains more than 10 points.}
  \label{fig:ratios}
\end{figure}

\subsubsection{Bin size dependency} % (fold)
\label{ssub:bin_size_dependency}
In the conventional Hough transform the weight function is calculated with respect to the bin centers of the accumulator space. The larger the binning in the accumulator space  is, the less accurate the calculations become. 
The number of bins is the main factor for the execution time of the algorithm. An advantage of this combinatorial approach lies in the 
fact that the parameters can be calculated accurately up to floating point precision and a histogram is only needed to group the results. 
A fine binning only marginally affects the execution time of the algorithm since the only operation done in the histogram is finding the 
maxima and this is only done a few times (stops when the found maximum is lower than the ring finding threshold).
% subsubsection bin_size_dependency (end)

% subsubsection optimisation (end)

\subsection{Possible optimisation: average radius of random circles in a unit square} % (fold)
\label{ssub:average_radius_of_random_circles_in_a_unit_square}
An interesting property of calculating the radius of circle candidates for triplets of random points that are distributed uniformely in the unit square is 
that they follow obey a certain distribution.

To prove this the average area $\overline{X}$ of a triangle formed by three points randomly chosen from the unit square\footnote{This proof is taken
from has to be calculated\cite{Blatter:2015}}. Let \( A = (A_x, A_y),\ B = (B_x, B_y),\ C = (C_x, C_y)\) be the vertices of the random triangle \( T \). We consider the case where \( A_y
> B_y > C_y \) which takes $\frac{1}{6}$ of the total ``volume'' of the unit square. Fix \( A_y, B_y, C_y \) for the moment and we can write
\[
  B_y = (1-t) A_y + t\cdot C_y, \qquad 0 \leq t \leq 1.
\]
The side $AC$ of $T$ intersects the horizontal level $y=B_y$ at the point $S=(s,B_y)$ with
\begin{equation}
  s = s(A_x,C_x,t) = (1-t)A_x + t\cdot C_x\label{eq:s}
\end{equation}
The area $X$ of $T$ is then given by
\[
  X = \frac{1}{2}\lvert B_x - s\rvert\cdot(C_y - A_y)
\]
We start integrate with respect to the six variables. The innermost integral is with respect to $B_x$ and gives

\begin{align}
  X_1 &:= \int_0^1XdB_x=\frac{1}{2}(C_y-A_y)\left( \int_0^s(s-B_x)dB_x + \int_s^1(B_x-s)dB_x\right)\nonumber\\
      &\phantom{:}= \frac{1}{4}(C_y-A_y)(1+2s+2s^2).\nonumber
\end{align}
Next we integrate over $B_y$:

\begin{align}
  X_2 &:= \int_{A_y}^{C_y}X_1dB_y = \frac{1}{4}(C_y-A_y)^2\int_0^1(1-2s+2s^2)dt,
\end{align}

whereby $s$ is given by Equation~\ref{eq:s}, and does not depend on $A_y$ and $C_y$. It follows that the intregration factorizes into
\begin{align}
  X_3 &:= \frac{1}{4}\int_0^1\int_{A_y}^1(C_y-A_y)^2\,dC_y\,dA_y\,\times\,\int_0^1\int_0^1\int_0^1(1-2s+2s^2)\,dt\,dC_x\,dA_x  \nonumber
\end{align}
This gives
\[
  X_3 = \frac{1}{4}\cdot \frac{1}{12} \cdot \frac{11}{18} = \frac{11}{6\cdot144}
\]
Generalizing the assumption at the beginning $A_y < B_y < C_y$, multiplying this result by $6$ and obtain $\overline{X}=\frac{11}{144}$.

From \cite{Weisstein2016} it follows that the average area of a triangle in a unit circle is $\frac{3}{2\pi}$. Dividing this by the area of the unit circle gives the expected fraction of the area covered by a triangle in an arbitrary circle

\[
\frac{\text{Expected area of a triangle in a unit circle}}{\text{Area of the unit circle}} = \underbrace{\frac{\frac{3}{2\pi}}{\pi r^2}}_{r=1} = \frac{3}{2\pi^2}
\]

Finally the average area of a random circle in the unit square can then be obtained by dividing the average area of a triangle from the unit square by the expected area covered by a triangle in an arbitrary circle:

\[
  \frac{\frac{11}{144}}{\frac{3}{2\pi^2}} = \frac{11\pi^2}{216}
\]

Finally this area should be equal to $\pi R^2$ where $R$ is the average radius of a random circle in the unit cube

\begin{align}
  R\pi^2 &= \frac{11\pi^2}{216}\nonumber\\
  R &= \sqrt{\frac{11\pi}{216}} = 0.399986\nonumber
\end{align}

Generating a data sample of randomly distributed points in the unit suqare and plotting the distribution of the radius calculated for this data set shows that there is indeed a peak around
 $R\approx 0.4$ as Figure~\ref{fig:rad_dist} shows.
 
The idea behind this is to generate a data sample with only background hits and prepare the radius histogram. It could then be used to subtract from a real radius histogram to reduce the number of bins that have to be searched since most of the background should be gone. However, this has yet to be studied properly.

 \begin{figure}[tb]
   \centering
   \includegraphics[width=0.8\textwidth]{sim_pics/radius_histogram_all}
   \caption[Radius distribution for background]{Radius distribution for uniformly generated 
    background. Each data set contains only randomly generated background hits. The expected value of $R\approx 0.4$
   is quite well represented for differently sized data sets}
   \label{fig:rad_dist}
 \end{figure}

% subsubsection average_radius_of_random_circles_in_a_unit_square (end)
% chapter methods (end)
\chapter{Results}
\label{cha:results}
In this section results for the conventional 1D, 2D and 3D Hough transform and 
for the combinatorial triplet Hough transform are presented. The 1D, 2D and 3D Hough transform
were not pursued in depth. They are presented here as they offer a 
way of understanding how each extra dimension expands the algorithm and shows the problems that occur with each added dimension.

For the 1D, 2D and 3D Hough transform only a small set of events consisting of:
\begin{itemize}
  \item 1 ring and 600 background hits
  \item 2 rings and 0 background hits
  \item 5 rings and 30 background hits
  \item 6 rings and 200 background hits (results only shown for 2D and 3D)
\end{itemize}
was Used . The number of points per ring and the distribution of the radiuses do not reflect the data obtained in LHC\textit{b}.

For these conventional Hough transforms following data sets were tested

The number of points per ring ranges from 17--31 and the background hits are uniformly distributed in the unit square. The event with 1
ring and 600 background hits is meant to test how robust the algorithm is with a 
lot of background hits. The second test case is meant to test if the algorithm can handle two ring objects, the third is a mix between several rings and background and the last event is a special case where two rings lie have similar radiuses and are close to each other, potentially creating problems for the 2D and 3D algorithms where the center coordinates are unkonwn. In Figure~\ref{fig:real_ht_results}
the real circles plotted from simulation parameters are shown for each of the events.

\begin{figure}
\centering
        \subfloat[][1 ring, 600 background hits.]{\includegraphics[width=0.5\textwidth]{sim_pics/1D_HT/real_result_1_circle_600_bg}}
                \label{fig:real_1c600bg}%
        \subfloat[][2 rings, 0 background hits]{\includegraphics[width=0.5\textwidth]{sim_pics/1D_HT/real_result_2_circles_0_bg}}
                \label{fig:real_2c0bg}

        \subfloat[][5 rings, 30 background hits]{\includegraphics[width=0.5\textwidth]{sim_pics/1D_HT/real_result_5_circles_30_bg}}
                \label{fig:real_5c30bg}%
        \subfloat[][6 rings, 200 background hits]{\includegraphics[width=0.5\textwidth]{sim_pics/2D_HT/real_result_6_circles_200_bg}}
                \label{fig:real_6c_200bg}%
        \caption{These are the test events as generated by the simulation.\label{fig:real_ht_results}}
\end{figure}

\section{1D Hough transform results} % (fold)
\label{sec:1d_hough_transform_results}

The radius scores for the first three test events are shown in Figures~\ref{fig:1_2_c_radius} and \ref{fig:1d_ht_radius}. The radius score is a 1D plot of the weight function defined in Equation~\ref{eq:weight_function}. The location of the highest score gives the value of the radius.
Figure~\ref{fig:1d_ht_results} shows the resulting circles in the ($x,y$) plane, using the known ring centers and the radiuses extracted by the algorithm. The numerical values of the highest and second highest score for each event are shown in Table~\ref{tab:1d_scores}. The highest and second highest score are well seperated in each case, the algorithm has no problems to find any of  the circles even with background. The fourth event was also tested for the 1D Hough transform but the results are not shown because they did not add anything that is not already covered with the first 3 events.

% subsection overview_of_the_results (end)
\begin{figure}[htp]
        \centering
        \subfloat[][1 ring, 600 background hits. \label{fig:1c600bg}]{\includegraphics[width=0.3\textwidth]{sim_pics/1D_HT/result_1_circle_600_bg}}
        ~ %add desired spacing between images, e. g. ~, \quad, \qquad etc.
          %(or a blank line to force the subfigure onto a new line)
       \subfloat[][2 rings, 0 background hits]{\includegraphics[width=0.3\textwidth]{sim_pics/1D_HT/result_2_circles_0_bg}}
                \label{fig:2c0bg}
        ~ %add desired spacing between images, e. g. ~, \quad, \qquad etc.
          %(or a blank line to force the subfigure onto a new line)
        \subfloat[][5 rings, 30 background hits]{\includegraphics[width=0.3\textwidth]{sim_pics/1D_HT/result_5_circles_30_bg}}
                \label{fig:5c30bg}
        \caption{Circles found by the 1D Hough transform.}\label{fig:1d_ht_results}
\end{figure}

\begin{table}[tbp]
  \caption[1D Radius scores for the different events]{Highest and second highest radius scores for the three events. There is always a big difference between the highest score
  which determines the circle and the second highest score which is due to noise.}
  \label{tab:1d_scores}
  \centering

  \begin{tabular}{lrr}
  \toprule

% Score: 7904.90875703
% Second highest score: 828.492365356
% Score: 6373.32098868
% Second highest score: 857.05517892



  \midrule
  \textbf{Event} & \textbf{Highest score} & \textbf{2nd highest score} \\
  \midrule
  \textbf{1 circle 600 background hits} & 8'546 & 3'798\\
  \midrule
  \textbf{2 circle 0 background hits} & 7'904 & 828\\
   & 6'373 & 857\\
  \midrule
  \textbf{5 circle 30 background hits} & 7'519 & 1'401\\
  & 9'085 & 1'476\\
  & 6'758 & 1'341\\
  & 7'381 & 848\\
  & 7'410 & 1'498\\
  \bottomrule
  \end{tabular}
\end{table}

% subsection 1d_hough_transform_2_circles_0_background (end)
\begin{figure}[htp]
        \centering
        \subfloat{\includegraphics[width=0.5\textwidth]{sim_pics/1D_HT/radius_scores_1_circle_600_bg_1}}

        \subfloat{\includegraphics[width=0.5\textwidth]{sim_pics/1D_HT/radius_scores_2_circles_0_bg_1}}
                \label{fig:2c0bg_radius1}%
        \subfloat{\includegraphics[width=0.5\textwidth]{sim_pics/1D_HT/radius_scores_2_circles_0_bg_2}}
                \label{fig:2c0b_radius2}
                \caption[1D Radius scores for two events]{Radius scores for 1 ring and 600 background hits (top) and 2 rings with 0 background hits (bottom). For the event
                with only 1 ring and 600 backgrounds hits the scores from background hits for a given radius are higher than in the other
                events with less noise but the correct radius has still a distinct peak.}
                \label{fig:1_2_c_radius}
\end{figure}
\begin{figure}[htb]
\centering
        \subfloat{\includegraphics[width=0.5\textwidth]{sim_pics/1D_HT/radius_scores_5_circles_30_bg_1}}
        \subfloat{\includegraphics[width=0.5\textwidth]{sim_pics/1D_HT/radius_scores_5_circles_30_bg_2}}
  
        \subfloat{\includegraphics[width=0.5\textwidth]{sim_pics/1D_HT/radius_scores_5_circles_30_bg_3}}
        \subfloat{\includegraphics[width=0.5\textwidth]{sim_pics/1D_HT/radius_scores_5_circles_30_bg_4}}

        \subfloat{\includegraphics[width=0.5\textwidth]{sim_pics/1D_HT/radius_scores_5_circles_30_bg_5}}
        \caption{Radius scores for the 1D Hough transform for the 5 rings with 0 background.}\label{fig:1d_ht_radius}
\end{figure}


% subsection 1d_hough_transform_5_circles_30_background_hits (end)


% section 1d_hough_transform_results (end)
\clearpage
\section{2D Hough transform} % (fold)
\label{sec:2d_hough_transform_results}
The 2D Hough transform uses again the weight function defined in Equation~\ref{eq:weight_function} to search for peaks with high
score in the ($x,y$) plane for known ring radiuses. Instead of a 1D histogram it is now a two dimensional histogram in which the highscore has to be found. Figure~\ref{fig:2d_slices} shows how a slice out of this plane looks like 
(similar to the 1D radius histogram).

The same events as for the 1D
Hough transform were investigated. Additionally the results for the event with 6 rings and 200 background hits are shown.

In Figures~\ref{fig:2D_HT_results1} and \ref{fig:2d_6c_200_bg2} the circles found by the algorithm are shown and in Table~\ref{tab:2d_scores} the highest and second highest score for each event are shown.
% subsection overview_of_the_results (end)

\begin{table}[tbp]
  \caption[2D Radius scores for the different events]{2D Radius scores for the different events.}
  \label{tab:2d_scores}
  \centering

  \begin{tabular}{lrr}
  \toprule
  \textbf{Event} & \textbf{Highest score} & \textbf{2nd highest score} \\
  \midrule
  \midrule
  \textbf{1 circle 600 background hits} & 8'720 & 5'778\\
  \midrule
  \textbf{2 circles 0 background hits} & 7'904 & 2'154\\
   & 6'373 & 2'275\\
  \midrule
  \textbf{5 circles 30 background hits} & 7'488 & 4'489\\
  & 9'095 & 3'717\\
  & 6'892 & 2'387\\
  & 6'498 & 2'373\\
  & 6'721 & 1'953\\
  \midrule
  \textbf{6 circles 200 background hits} & 11'869 & 5'583\\
  & 10'466 & 8'687\\
  & 8'762 & 5'790\\
  & 6'872 & 5'203\\
  & 10'155  & 3'595\\
  & 4'764 &  3'759\\
  \bottomrule
  \end{tabular}
\end{table}

\begin{figure}[htp]
        \centering
        \subfloat[][1 ring, 600 background hits.\label{fig:2d_1c600bg}]{\includegraphics[width=0.3\textwidth]{sim_pics/2D_HT/result_1_circle_600_bg}}
        ~ %add desired spacing between images, e. g. ~, \quad, \qquad etc.
          %(or a blank line to force the subfigure onto a new line)
        \subfloat[][2 rings, 0 background hits\label{fig:2d_2c0bg}]{\includegraphics[width=0.3\textwidth]{sim_pics/2D_HT/result_2_circles_0_bg}}
        ~ %add desired spacing between images, e. g. ~, \quad, \qquad etc.
          %(or a blank line to force the subfigure onto a new line)
        \subfloat[][5 rings, 30 background hits  \label{fig:2d_5c30bg}]{\includegraphics[width=0.3\textwidth]{sim_pics/2D_HT/result_5_circles_30_bg}}
              
        \caption{Circles found by the 2D Hough transform.}\label{fig:2D_HT_results1}

        \subfloat{\includegraphics[width=0.5\textwidth]{sim_pics/2D_HT/real_result_6_circles_200_bg}}
        \subfloat{\includegraphics[width=0.5\textwidth]{sim_pics/2D_HT/result_6_circles_200_bg_newsig}}
        \caption{The rings generated by the simulation (left) and the rings found by the algorithm (right). The blue colored circle found by the algorithm is incorrect.}
        \label{fig:2d_6c_200_bg2}
\end{figure}

\subsection{1 ring, 600 background hits} % (fold)
\label{sub:1_ring_600_background_hits}
The ring was found by the algorithm. The highest and second highest score are well separated. 
% subsection 1_ring_600_background_hits (end)

\subsection{2 rings, 0 background hits} % (fold)
\label{sub:2d_hough_transform_2_circles_0_background}
Both rings are found in this event. Two cirlces pose no problem unless the two rings have the same radius. If that is the case the algorithm will find the same circle twice unless there is a mechanism that avoids this. Assume the two rings have radius $r$ and the algorithm calculates the weight matrix for the possible center coordinates. There will be two peaks, one for each ring. One peak will have a higher score and the algorithm extracts the coordinates of the peak. After that the algorithm searches the center for the second circle but since both circles have the same radius it will have the same scores again and find the first circle once more. Introducing a mechanism that removes points that were assigned to a circle solves this problem.

\begin{figure}[htp]
        \centering
        \begin{tikzpicture}
          \node[anchor=south west,inner sep=0] (image) at (0,0) {\includegraphics[width=0.5\linewidth]{sim_pics/2D_HT/center_scores_2_circles_0_bg_2_properlabels.png}};
          % \begin{scope}[x={(image.south east)},y={(image.north west)}]
          %       \draw[white,thick,->] (0.62,0.4) -- (0.56,0.31);
          % \end{scope}
        \end{tikzpicture}%
        \begin{tikzpicture}
          \node[anchor=south west,inner sep=0] (image) at (0,0) {\includegraphics[width=0.5\linewidth]{sim_pics/2D_HT/center_scores_2_circles_0_bg_1_properlabels.png}};
          % \begin{scope}[x={(image.south east)},y={(image.north west)}]
          %       \draw[white,thick,->] (0.6,0.5) -- (0.68,0.555);
          % \end{scope}
        \end{tikzpicture}
        \caption{Center score for the 2D Hough transform for 2 rings with 0 background.}\label{fig:2d_ht_center}

        \includegraphics[width=0.5\textwidth]{sim_pics/2D_HT/projection/stacked_projection_9_2}%
        \includegraphics[width=0.5\textwidth]{sim_pics/2D_HT/projection/stacked_projection_9_1}
        \caption[Two slices out of the 2D histogram]{Horizontal slices (fixed $c_y$) around the maximum values out
        of the 2D histogram for the event with 2 circles and no background.}\label{fig:2d_slices}
\end{figure}

% subsection 2d_hough_transform_2_circles_0_background (end)

\subsection{5 rings, 30 background hits} % (fold)
\label{sub:2d_hough_transform_5_circles_30_background_hits}

The algorithm had no problems finding all the circles. In Figure~\ref{fig:2d_5_circles_30_bg_radius} the score histograms are shown.

\begin{figure}[htbp]
  \centering
  \begin{tikzpicture}
  \node[anchor=south west,inner sep=0] (image) at (0,0) {\includegraphics[width=0.5\textwidth]{sim_pics/2D_HT/center_scores_5_circles_30_bg_1_properlabels.png}};
  % \begin{scope}[x={(image.south east)},y={(image.north west)}]
  %       \draw[white,thick,->] (0.6,0.5) -- (0.68,0.555);
  % \end{scope}
  \end{tikzpicture}%
  \begin{tikzpicture}
  \node[anchor=south west,inner sep=0] (image) at (0,0) {\includegraphics[width=0.5\textwidth]{sim_pics/2D_HT/center_scores_5_circles_30_bg_2_properlabels.png}};
  % \begin{scope}[x={(image.south east)},y={(image.north west)}]
  %       \draw[white,thick,->] (0.6,0.5) -- (0.68,0.555);
  % \end{scope}
  \end{tikzpicture}

  \begin{tikzpicture}
  \node[anchor=south west,inner sep=0] (image) at (0,0) {\includegraphics[width=0.5\textwidth]{sim_pics/2D_HT/center_scores_5_circles_30_bg_3_properlabels.png}};
  % \begin{scope}[x={(image.south east)},y={(image.north west)}]
  %       \draw[white,thick,->] (0.6,0.5) -- (0.68,0.555);
  % \end{scope}
  \end{tikzpicture}%
  \begin{tikzpicture}
  \node[anchor=south west,inner sep=0] (image) at (0,0) {\includegraphics[width=0.5\textwidth]{sim_pics/2D_HT/center_scores_5_circles_30_bg_4_properlabels.png}};
  % \begin{scope}[x={(image.south east)},y={(image.north west)}]
  %       \draw[white,thick,->] (0.6,0.5) -- (0.68,0.555);
  % \end{scope}
  \end{tikzpicture}

  \begin{tikzpicture}
  \node[anchor=south west,inner sep=0] (image) at (0,0) {\includegraphics[width=0.5\textwidth]{sim_pics/2D_HT/center_scores_5_circles_30_bg_5_properlabels.png}};
  % \begin{scope}[x={(image.south east)},y={(image.north west)}]
  %       \draw[white,thick,->] (0.6,0.5) -- (0.68,0.555);
  % \end{scope}
  \end{tikzpicture}
  \caption{Scores in the ($c_x,c_y$) plane found by the 2D Hough transform for the event with 5 rings and 30 background hits.}
  \label{fig:2d_5_circles_30_bg_radius}
\end{figure}

% subsection 2d_hough_transform_5_circles_30_background_hits (end)

\subsection{6 rings, 200 background hits} % (fold)
\label{sub:2d_hough_transform_6_circles_200_background_hits}
As briefly discussed in the overview the algorithm does make mistakes as this event shows. 6 circles were generated with 200 background hits. The interesting part is not that amount of circles or the amount of background hits are the problem but the properties of the circles (center coordinate and radius). In this example there is a misidentification of a circle with points of another.

The reason for the wrong detection of the cirle is quite simple. Two of the circles have very similar radiuses. The algorithm looks first for the blue circle (because that happens to be the way the centers are arranged in the list) and since so many points of the magenta circle lie so close together it is easy for the blue circle (who has a similar radius) 
to get a high score with these points, a higher score than it would get with its proper points. If the magenta points were more evenly 
distributed on the circle or if there were more blue points this probably would not happen but that is something that cannot be controlled.

Theoretically it is also possible that the magenta circle gets fitted to the
blue points but since there are still enough magenta points left after the removal 
of the points assigned to the blue circle they still have the highest score with 
their own points and the blue circle goes unnoticed.

Also, if the magenta circle would be checked before blue then the algorithm
would find the proper circles as well. So it actually can depend on the order
in which the circles are searched.
% subsection 2d_hough_transform_6_circles_200_background_hits (end)

\begin{figure}
\centering
  \begin{tikzpicture}
  \node[anchor=south west,inner sep=0] (image) at (0,0) {\includegraphics[width=0.3\textwidth]{sim_pics/2D_HT/center_scores_6_circles_200_bg_1_properlabels_newsig.png} };
  % \begin{scope}[x={(image.south east)},y={(image.north west)}]
  %       \draw[white,thick,->] (0.6,0.5) -- (0.68,0.555);
  % \end{scope}
  \end{tikzpicture}%
  \begin{tikzpicture}
  \node[anchor=south west,inner sep=0] (image) at (0,0) { \includegraphics[width=0.3\textwidth]{sim_pics/2D_HT/center_scores_6_circles_200_bg_2_properlabels_newsig.png}};
  % \begin{scope}[x={(image.south east)},y={(image.north west)}]
  %       \draw[white,thick,->] (0.6,0.5) -- (0.68,0.555);
  % \end{scope}
  \end{tikzpicture}%
  \begin{tikzpicture}
  \node[anchor=south west,inner sep=0] (image) at (0,0) {\includegraphics[width=0.3\textwidth]{sim_pics/2D_HT/center_scores_6_circles_200_bg_3_properlabels_newsig.png} };
  % \begin{scope}[x={(image.south east)},y={(image.north west)}]
  %       \draw[white,thick,->] (0.6,0.5) -- (0.68,0.555);
  % \end{scope}
  \end{tikzpicture}

  \begin{tikzpicture}
  \node[anchor=south west,inner sep=0] (image) at (0,0) {\includegraphics[width=0.3\textwidth]{sim_pics/2D_HT/center_scores_6_circles_200_bg_4_properlabels_newsig.png} };
  % \begin{scope}[x={(image.south east)},y={(image.north west)}]
  %       \draw[white,thick,->] (0.2,0.5) -- (0.1,0.5);
  % \end{scope}
  \end{tikzpicture}%
  \begin{tikzpicture}
  \node[anchor=south west,inner sep=0] (image) at (0,0) {\includegraphics[width=0.3\textwidth]{sim_pics/2D_HT/center_scores_6_circles_200_bg_5_properlabels_newsig.png} };
  % \begin{scope}[x={(image.south east)},y={(image.north west)}]
  %       \draw[white,thick,->] (0.6,0.5) -- (0.68,0.555);
  % \end{scope}
  \end{tikzpicture}%
  \begin{tikzpicture}
  \node[anchor=south west,inner sep=0] (image) at (0,0) {\includegraphics[width=0.3\textwidth]{sim_pics/2D_HT/center_scores_6_circles_200_bg_6_properlabels_newsig.png} };
  % \begin{scope}[x={(image.south east)},y={(image.north west)}]
  %       \draw[white,thick,->] (0.6,0.5) -- (0.68,0.555);
  % \end{scope}
  \end{tikzpicture}
  \caption[Center scores for 6 circles with 200 background hits.]{Scores in the ($c_x,c_y$) plane found by the algorithm for 6 circles with 200 background hits.}

  \subfloat{\includegraphics[width=0.5\textwidth]{sim_pics/2D_HT/result_6_circles_200_bg_newsig}}
  \subfloat{\includegraphics[width=0.5\textwidth]{sim_pics/2D_HT/real_result_6_circles_200_bg}}
\caption{On the left side the wrong result obtained by the 2D Hough transform and the correct one on the right side}\label{fig:6c_200_bg_results}
\end{figure}

A possible way to fix this particular problem seemed tuning the parameter of the weight function namely reducing the standard deviation. 
\[
  w(\eta) = \frac{1}{\sqrt{2\pi}\sigma}\exp\left( \frac{-\eta^2}{2\sigma^2}\right)
\]
Having a higher $\sigma$ means that a point that is a bit off of the circle still contributes a considerable value to the total score. 
The smaller the $\sigma$ is the sharper the peak. However if the peak is too sharp then the algorithm might discard possible results 
because they are just a bit off the circle and since the peak is so narrow they do not contribute at all to the total score.

Tests with this event have shown that varying the $\sigma$ parameter was not the leading factor in finding the circle. Even with the smaller $\sigma$ the algorithm often failed to find the right circles. However, changing the order of the radiuses in which they appear in the list caused the algorithm to find the right circles without changing the $\sigma$.
%comment:
% order of the circles:
% 0.141
% 0.158
% 0.144
% 0.153
% 0.144
% 0.157

% \begin{figure}
% \centering
%   \includegraphics[width=0.5\textwidth]{sim_pics/2D_HT/real_result_6_circles_200_bg}
%   \caption[2D HT:  6 circles, 200 background hits results]{This time with the new $\sigma = 0.0005$ the algorithm is capable to solve
% this event correctly.}\label{2d_result_6c_200bg_corr}
% \end{figure}

% section 2d_hough_transform_results (end)
\clearpage
\section{3D Hough transform Results} % (fold)
\label{sec:3d_hough_transform_results}
The 3D Hough transform has to deal with 3 unknown parameters: ($x,y,r$), and the fact that the number of rings is unknown. As explained in Section~\ref{sub:3d_nothing_is_known_find_everything}, a threshold is needed to decide when the algorithm
should stop finding a circle. This value depends heavily on the value of the parameter $\sigma$ of the weight function. Here the $\sigma$ was set to $0.001$ and the threshold was set to $3500$. This threshold was determined by looking at the scores of different circles with varying number of points per circle. After testing the algorithm for different events and comparing their scores this threshold found all the circles.
Plots of the found circle for the four tested events are shown in Figure~\ref{fig:3D_HT_results}.


\begin{figure}[htp]
        \centering
        \subfloat[][1 ring, 600 background hits.\label{fig:3D_1c_600bg}]{\includegraphics[width=0.5\textwidth]{sim_pics/3D_HT/result_1_circle_600_bg}}%
        \subfloat[][2 rings, 0 background hits]{\includegraphics[width=0.5\textwidth]{sim_pics/3D_HT/result_2_circles_0_bg}}

        \subfloat[][5 rings, 30 background hits]{\includegraphics[width=0.5\textwidth]{sim_pics/3D_HT/result_5_circles_30_bg}}
        \subfloat[][6 rings, 200 background hits]{\includegraphics[width=0.5\textwidth]{sim_pics/3D_HT/result_6_circles_200_bg}}
        \caption[Circles found by the 3D Hough transform]{Circles found by the 3D Hough transform.\label{fig:3D_HT_results}}
\end{figure}


\subsection{Overview of the results} % (fold)
\label{ssub:3d_overview_of_the_results}

The 3D Hough transform algorithm solves three of the four events correctly. The event that failed was that with 1 circle and 600 background hits where the signal to noise ratio was too small for the algorithm to isolate the correct solution. In Table~\ref{tab:3d_10_high_scores} the results for the 10 highest scores are shown. The threshold was set to $3500$. The obvious fix seems to set the threshold to a higher value (e.g. $6300$) so the algorithm would not pick up any fake rings. However, with a threshold that high legit rings from other events would get lost. For a fixed threshold there will always be a case where rings get lost or fake rings get picked up. Quantitative study would require to process a larger amount of events which is not done here since the focus in this thesis is on the triplet approach. On the other hand the 3D Hough transform managed to solve the 6 circles with 200 background hits despite having less information. This is probably due to the fact that the 3D Hough transform finds the circles sorted by score and does not depend on the order in which circles are searched (remember, in the 2D case the radius is given and depending on which radius is given first we can solve it correctly or not).

\begin{table}[htp]
\centering
\caption[Circle scores for 1 ring 600 background hits]{The ten highest scores found by the 3D Hough transform for the event with 1 ring and 600 background hits.}
\label{tab:3d_10_high_scores}
\begin{tabular}{c|c|c|c}
\toprule
8'122 & 6'256 & 5'672 & 5'654 \\
5'373 & 5'290 & 5'047 & 5'000 \\
4'727 & 4'647 &  &  \\
\bottomrule
\end{tabular}
\end{table}

\begin{table}[tbp]
  \caption[3D Hough transform scores]{Highest scores and the first fake score for the 3D Hough transform.}
  \label{tab:3d_scores}
  \centering

  \begin{tabular}{p{5cm}rr}
  \toprule
   & \textbf{Scores fo the true rings}  & \textbf{Highest fake ring score}\\
  \midrule
  \midrule
  \multicolumn{3}{l}{\textbf{1 circle 600 background hits}} \\
  & 8'122 \\
   &  & 6'265\\
  \midrule
  \multicolumn{3}{l}{\textbf{2 circles 0 background hits}}\\
   & 7'332 \\
   & 5'601 \\
   \multicolumn{3}{r}{No fakes found}\\
  \midrule
  \multicolumn{3}{l}{\textbf{5 circles 30 background hits}}\\
  & 8'170 \\
  & 6'979 \\
  & 6'477 \\
  & 4'416 \\
  & 3'536 \\
   &  & 2'712 \\
  \midrule
  \multicolumn{3}{l}{\textbf{6 circles 200 background hits}}\\
  & 10'269 \\
  & 9'050 \\
  & 8'505 \\
  & 8'258 \\
  & 5'836 \\
  & 3'944 \\
   & & 3'485 \\
   \bottomrule
  \end{tabular}
\end{table}



% section 3d_hough_transform_results (end)
\clearpage
\section{Combinatorial triplet Hough transform} % (fold)
\label{sec:combinatorial_approach_results}

This method was tested against a set of 10'000 events generated in a Monte-Carlo simulation with parameters (number of rings, number of points per ring, number of noise points) tuned to reproduce distributions measured in LHC\textit{b}. The whole set was tested several times, with different thresholds for the radius and center histograms. 
Each of these runs used the method of splitting the data point list into two lists and building triplets from 
the sublists as discussed in \ref{ssub:improvement_of_speed}. The results show that this choice yielded an efficiency above $98\%$. 
The performance was evaluated with an analysis script to measure the efficiency $\epsilon$ and ghost rate $\gamma$.

The efficiency is defined as 
\begin{equation}
\epsilon = 1 - \frac{m}{T}    
\end{equation}
where $m$ is the number of circles that were not found by the algorithm and $T$ is the true number of rings from summed over all events. The ghost rate is defined as 
\begin{equation}
  \gamma = \frac{f}{T} 
\end{equation}
where $f$ is the number of fake circles that were found by the algorithm but have no match in the test data and $T$ again the
total number of circles.


\subsection{Ring finding threshold} % (fold)
\label{sub:different_thresholds2}

In Table~\ref{tab:threshold_cuts} the different efficiencies for the algorithm for different values of the threshold can be seen. 
Intuitively one expects the ghost rate to increase at low threshold since it is more likely for random combinations of triplets to pass the threshold. With increasing threshold the efficiency will drop when legit rings fall below the threshold. 

\begin{figure}[tb]
  \centering
  \includegraphics[width=0.6\textwidth]{sim_pics/ratio_ppc}
  \caption{Reversed cumulative distribution of the points per circle. The plot shows the ratio of circles with more than $N$ points over the
  total number of circles}
  \label{fig:ratio_ppc}
\end{figure}


\begin{table}[tb]
  \caption[Efficiencies for different thresholds]{Efficiency and ghost rate for different thresholds (radius and center cuts are fixed at $0.006$). The ghost fraction explodes when the ring finding threshold is too low.}
  \label{tab:threshold_cuts}
  \centering

  \begin{tabular}{lcrcr}
  \toprule
  \textbf{Threshold} & $\boldsymbol{\epsilon}$ & \textbf{Missed} & $\boldsymbol{\gamma}$ & \textbf{Fakes} \\
  \midrule
  20  & 99.99\% & 7 & 183.22\% & 91573 \\
  35  & 99.98\% & 9 & 131.50\% & 65723 \\
  56  & 99.97\% & 16 & 9.07\% & 4533 \\
  84  & 99.92\% & 41 & 2.13\% & 1067 \\
  165 & 99.57\% & 214 & 0.13\% & 66 \\
  220 & 99.18\% & 410 & 0.05\% & 27 \\
  286 & 98.43\% & 784 & 0.01\% & 4 \\
  \bottomrule
  \end{tabular}
\end{table}

% subsection different_thresholds (end)

\subsection{Cuts for removing duplicates} % (fold)
\label{sub:different_cuts_for_circle_selection}

Additional circles can get lost because they get identified as duplicate when they are in fact just another distinct circle in 
the vicinity of another circle. Duplicate circles that are typically created with a major fraction of points of a circle and for 
example a single background hit that is just far enough off that the radius and center histogram show it as a distinct circle. 
In Code Snippet~\ref{pc:dup_code} the duplicate removal is shown. First all ring candidates are sorted ascending by number of 
entries they had in the center histogram. The first circle is then popped from the list and is compared to all the remaining circles 
in the list. If the circle is within the threshold distance (see Equations in~\ref{eq:cut1}) the circle is flagged as not unique and 
the comparison for the rest of the circles stop. 

\subsection{Comparing algorithm with the data}

The parameters to evaluated the performance of the algorithm are:
\begin{itemize}
	\item Distance between the center of a calculated ring and the corresponding true ring
	\item Difference between calculated radius and the true radius of a ring
\end{itemize}
They are used to decide whether or not the algorithm has found a circle. The reconstructed radius and center coordinates are compared with the true test in the test data. If a circle is within these bounds the circle will be considered as found. In a real application
however, these parameters are useless because a priori there is no knowledge about the true circles.

\subsubsection{Cut variation for a fixed ring finding threshold} % (fold)
\label{ssub:cut_variation_for_a_fixed_threshold}
In Tables \ref{tab:cut_variation_1} and \ref{tab:cut_variation_2} different cut parameters were tested
and compared for the efficiency and ghost rate.

\begin{table}[htbp]
  \caption{Efficiency and ghost rate for a fixed radius cut (0.003) and ring finding threshold (120) with varying center cut. The tighter the center cut is
  the more duplicate circles remain after the clean up.}
  \label{tab:cut_variation_1}
  \centering

  \begin{tabular}{lcrcr}
  \toprule
  \textbf{$C$ cut} & $\boldsymbol{\epsilon}$ & \textbf{Missed} & $\boldsymbol{\gamma}$ & \textbf{Fakes} \\
  \midrule
  0.003 & 99.19\% & 405 & 0.17\% & 86 \\
  0.006 & 99.19\% & 407 & 0.12\% & 62 \\
  0.009 & 99.18\% & 409 & 0.12\% & 60 \\
  0.012 & 99.17\% & 415 & 0.12\% & 60 \\
    \bottomrule
  \end{tabular}
\end{table}

\begin{table}[htbp]
  \caption{Reducing ghost rate for a fixed center cut (0.003) with varying center cut. The tighter the center cut is
  the more duplicate circles fail being detected by the removeDuplicate code shown above}
  \label{tab:cut_variation_2}
  \centering

  \begin{tabular}{lcrcr}
  \toprule
  \textbf{$R$ cut} & $\boldsymbol{\epsilon}$ & \textbf{Missed} & $\boldsymbol{\gamma}$ & \textbf{Fakes} \\
  \midrule
  0.003 & 99.19\% & 405 & 0.17\% & 86 \\
  0.006 & 99.19\% & 405 & 0.15\% & 77 \\
  0.009 & 99.19\% & 405 & 0.15\% & 77 \\
  0.012 & 99.19\% & 405 & 0.15\% & 76 \\
  \bottomrule
  \end{tabular}
\end{table}

Tables~\ref{tab:longtable} show all combinations of cuts for both radius and center ranging from $0.003$ to
$0.0012$ in steps of $0.003$ for different ring finding thresholds. 
\newpage
\begin{longtable}{llcrcr}
\caption{Results for all the cut combinations for radius and center cuts}\label{tab:longtable}\\
\toprule
\multicolumn{6}{c}{\textbf{Threshold = 35} (7 points for a circle)}\\
\midrule
\textbf{$R$ cut} & \textbf{$C$ cut} & $\boldsymbol{\epsilon}$ & \textbf{Missed} & $\boldsymbol{\gamma}$ & \textbf{Fakes} \\
\midrule
%run03
0.003 & 0.003 & 99.99\% & 4 & 178.96\% & 89444 \\
0.003 & 0.006 & 99.99\% & 6 & 151.62\% & 75777 \\
0.003 & 0.009 & 99.98\% & 8 & 144.59\% & 72264 \\
0.003 & 0.012 & 99.97\% & 13 & 140.88\% & 70408 \\
0.006 & 0.003 & 99.99\% & 4 & 174.01\% & 86968 \\
0.006 & 0.006 & 99.98\% & 9 & 131.50\% & 65723 \\
0.006 & 0.009 & 99.96\% & 19 & 118.91\% & 59432 \\
0.006 & 0.012 & 99.94\% & 28 & 113.54\% & 56745 \\
0.009 & 0.003 & 99.99\% & 4 & 173.53\% & 86729 \\
0.009 & 0.006 & 99.98\% & 12 & 130.54\% & 65244 \\
0.009 & 0.009 & 99.95\% & 25 & 112.21\% & 56079 \\
0.009 & 0.012 & 99.93\% & 36 & 103.50\% & 51727 \\
0.012 & 0.003 & 99.99\% & 4 & 173.30\% & 86612 \\
0.012 & 0.006 & 99.97\% & 15 & 130.26\% & 65103 \\
0.012 & 0.009 & 99.94\% & 32 & 111.64\% & 55795 \\
0.012 & 0.012 & 99.91\% & 47 & 99.85\% & 49902 \\
\bottomrule
\toprule
\multicolumn{6}{c}{\textbf{Threshold = 56} (8 points for a circle)}\\
\midrule
\textbf{$R$ cut} & \textbf{$C$ cut} & $\boldsymbol{\epsilon}$ & \textbf{Missed} & $\boldsymbol{\gamma}$ & \textbf{Fakes} \\
\midrule
%run02
0.003 & 0.003 & 99.98\% & 11 & 20.54\% & 10264 \\
0.003 & 0.006 & 99.97\% & 13 & 14.52\% & 7255 \\
0.003 & 0.009 & 99.97\% & 15 & 13.59\% & 6792 \\
0.003 & 0.012 & 99.96\% & 21 & 13.24\% & 6616 \\
0.006 & 0.003 & 99.98\% & 11 & 19.23\% & 9611 \\
0.006 & 0.006 & 99.97\% & 16 & 9.07\% & 4533 \\
0.006 & 0.009 & 99.95\% & 26 & 7.29\% & 3641 \\
0.006 & 0.012 & 99.93\% & 35 & 6.82\% & 3409 \\
0.009 & 0.003 & 99.98\% & 11 & 19.14\% & 9568 \\
0.009 & 0.006 & 99.96\% & 19 & 8.91\% & 4454 \\
0.009 & 0.009 & 99.94\% & 32 & 5.90\% & 2950 \\
0.009 & 0.012 & 99.91\% & 43 & 4.94\% & 2467 \\
0.012 & 0.003 & 99.98\% & 11 & 19.10\% & 9544 \\
0.012 & 0.006 & 99.96\% & 22 & 8.87\% & 4432 \\
0.012 & 0.009 & 99.92\% & 39 & 5.81\% & 2906 \\
0.012 & 0.012 & 99.89\% & 54 & 4.29\% & 2143 \\
\bottomrule
\toprule
\multicolumn{6}{c}{\textbf{Threshold = 84} (9 points for a circle)}\\
\midrule
\textbf{$R$ cut} & \textbf{$C$ cut} & $\boldsymbol{\epsilon}$ & \textbf{Missed} & $\boldsymbol{\gamma}$ & \textbf{Fakes} \\
\midrule
%run01
0.003 & 0.003 & 99.93\% & 36 & 5.82\% & 2911 \\
0.003 & 0.006 & 99.92\% & 38 & 4.00\% & 1999 \\
0.003 & 0.009 & 99.92\% & 40 & 3.80\% & 1900 \\
0.003 & 0.012 & 99.91\% & 46 & 3.72\% & 1861 \\
0.006 & 0.003 & 99.93\% & 36 & 5.37\% & 2682 \\
0.006 & 0.006 & 99.92\% & 41 & 2.13\% & 1067 \\
0.006 & 0.009 & 99.90\% & 51 & 1.66\% & 830 \\
0.006 & 0.012 & 99.88\% & 60 & 1.57\% & 787 \\
0.009 & 0.003 & 99.93\% & 36 & 5.34\% & 2671 \\
0.009 & 0.006 & 99.91\% & 44 & 2.09\% & 1044 \\
0.009 & 0.009 & 99.89\% & 57 & 1.27\% & 636 \\
0.009 & 0.012 & 99.86\% & 68 & 1.07\% & 534 \\
0.012 & 0.003 & 99.93\% & 36 & 5.33\% & 2665 \\
0.012 & 0.006 & 99.91\% & 47 & 2.08\% & 1040 \\
0.012 & 0.009 & 99.87\% & 64 & 1.25\% & 626 \\
0.012 & 0.012 & 99.84\% & 79 & 0.88\% & 439 \\
\bottomrule
\toprule
\multicolumn{6}{c}{\textbf{Threshold = 165} (11 points for a circle)}\\
\midrule
\textbf{$R$ cut} & \textbf{$C$ cut} & $\boldsymbol{\epsilon}$ & \textbf{Missed} & $\boldsymbol{\gamma}$ & \textbf{Fakes} \\
\midrule
%run05
0.003 & 0.003 & 99.58\% & 209 & 0.48\% & 238 \\
0.003 & 0.006 & 99.58\% & 211 & 0.32\% & 162 \\
0.003 & 0.009 & 99.57\% & 213 & 0.31\% & 156 \\
0.003 & 0.012 & 99.56\% & 219 & 0.31\% & 155 \\
0.006 & 0.003 & 99.58\% & 209 & 0.42\% & 209 \\
0.006 & 0.006 & 99.57\% & 214 & 0.13\% & 66 \\
0.006 & 0.009 & 99.55\% & 224 & 0.10\% & 50 \\
0.006 & 0.012 & 99.53\% & 233 & 0.10\% & 49 \\
0.009 & 0.003 & 99.58\% & 209 & 0.42\% & 209 \\
0.009 & 0.006 & 99.57\% & 217 & 0.13\% & 64 \\
0.009 & 0.009 & 99.54\% & 230 & 0.07\% & 34 \\
0.009 & 0.012 & 99.52\% & 241 & 0.05\% & 26 \\
0.012 & 0.003 & 99.58\% & 209 & 0.42\% & 208 \\
0.012 & 0.006 & 99.56\% & 220 & 0.13\% & 64 \\
0.012 & 0.009 & 99.53\% & 237 & 0.07\% & 34 \\
0.012 & 0.012 & 99.50\% & 252 & 0.04\% & 18 \\
\bottomrule
\toprule
\multicolumn{6}{c}{\textbf{Threshold = 220} (12 points for a circle)}\\
\midrule
\textbf{$R$ cut} & \textbf{$C$ cut} & $\boldsymbol{\epsilon}$ & \textbf{Missed} & $\boldsymbol{\gamma}$ & \textbf{Fakes} \\
\midrule
%run06
0.003 & 0.003 & 99.19\% & 405 & 0.17\% & 86 \\
0.003 & 0.006 & 99.19\% & 407 & 0.12\% & 62 \\
0.003 & 0.009 & 99.18\% & 409 & 0.12\% & 60 \\
0.003 & 0.012 & 99.17\% & 415 & 0.12\% & 60 \\
0.006 & 0.003 & 99.19\% & 405 & 0.15\% & 77 \\
0.006 & 0.006 & 99.18\% & 410 & 0.05\% & 27 \\
0.006 & 0.009 & 99.16\% & 420 & 0.04\% & 21 \\
0.006 & 0.012 & 99.14\% & 429 & 0.04\% & 21 \\
0.009 & 0.003 & 99.19\% & 405 & 0.15\% & 77 \\
0.009 & 0.006 & 99.17\% & 413 & 0.05\% & 25 \\
0.009 & 0.009 & 99.15\% & 426 & 0.02\% & 11 \\
0.009 & 0.012 & 99.13\% & 437 & 0.02\% & 9 \\
0.012 & 0.003 & 99.19\% & 405 & 0.15\% & 76 \\
0.012 & 0.006 & 99.17\% & 416 & 0.05\% & 25 \\
0.012 & 0.009 & 99.13\% & 433 & 0.02\% & 11 \\
0.012 & 0.012 & 99.10\% & 448 & 0.01\% & 6 \\
\bottomrule
\toprule
\multicolumn{6}{c}{\textbf{Threshold = 286} (13 points for a circle)}\\
\midrule
\textbf{$R$ cut} & \textbf{$C$ cut} & $\boldsymbol{\epsilon}$ & \textbf{Missed} & $\boldsymbol{\gamma}$ & \textbf{Fakes} \\
\midrule
%run07
0.003 & 0.003 & 98.44\% & 779 & 0.05\% & 25 \\
0.003 & 0.006 & 98.44\% & 781 & 0.03\% & 17 \\
0.003 & 0.009 & 98.43\% & 783 & 0.03\% & 16 \\
0.003 & 0.012 & 98.42\% & 789 & 0.03\% & 16 \\
0.006 & 0.003 & 98.44\% & 779 & 0.04\% & 21 \\
0.006 & 0.006 & 98.43\% & 784 & 0.01\% & 4 \\
0.006 & 0.009 & 98.41\% & 794 & 0.01\% & 3 \\
0.006 & 0.012 & 98.39\% & 803 & 0.01\% & 3 \\
0.009 & 0.003 & 98.44\% & 779 & 0.04\% & 21 \\
0.009 & 0.006 & 98.43\% & 787 & 0.01\% & 4 \\
0.009 & 0.009 & 98.40\% & 800 & 0.00\% & 2 \\
0.009 & 0.012 & 98.38\% & 811 & 0.00\% & 2 \\
0.012 & 0.003 & 98.44\% & 779 & 0.04\% & 21 \\
0.012 & 0.006 & 98.42\% & 790 & 0.01\% & 4 \\
0.012 & 0.009 & 98.39\% & 807 & 0.00\% & 2 \\
0.012 & 0.012 & 98.36\% & 822 & 0.00\% & 2 \\
\bottomrule
\end{longtable}

These results show that the most important parameter for changing the ghost rate is the ring finding threshold.
If this threshold is too low, too many fake rings are found from random point combination that happen to lie close to a circle.

The main reason for missed rings is again the ring finding threshold since it limits the number of rings
being found. Since the algorithm uses two split lists, the number of missed circles is even slightly higher due to the
fact that sometimes the points of a circle can be split just in a way that the two lists do not
contain enough points individually to create an accepted circle (see subsection \ref{sub:different_thresholds}).
% subsubsection cut_variation_for_a_fixed_threshold (end)
% subsection different_cuts_for_circle_selection (end)
\subsection{Excecution time} % (fold)
\label{sub:runtime}

The execution time of the whole algorithm depends strongly on the number of data points. The runtime ranges from several seconds to several minutes as shown in Figure~\ref{fig:runtime}. The algorithm was run on the farm-ui cluster of the University of Zurich. The worknodes are not identical. This could explain why there is branching in the runtime when some nodes are slightly quicker than the other. The fit in the plot is $1.8e{-}5\frac{N^3}{6}$ where $N$ is the number of data points to show the dependency of the runtime on the points. The constant factor was determined by trial and error but is for all the plots the same.

\begin{figure}[tb]
  \centering
  \includegraphics[width=0.5\textwidth]{sim_pics/runtime_vs_points_run01}%
  \includegraphics[width=0.5\textwidth]{sim_pics/runtime_vs_points_run02}

  \includegraphics[width=0.5\textwidth]{sim_pics/runtime_vs_points_run03}%
  \includegraphics[width=0.5\textwidth]{sim_pics/runtime_vs_points_run04}
  \caption[Runtimes of four different runs]{Runtimes of four different runs with differend ring finding thresholds. }
  \label{fig:runtime}
\end{figure}
% subsection runtime (end)

% section combinatorial_approach_results (end)



% chapter results (end)

\chapter{Conclusions} % (fold)
\label{cha:conclusions}

This thesis studied different Hough transforms for ring detection in the LHC\textit{b} detector. In a first approach a 1D Hough 
transform was used and then extended to two and three dimensions.
As a fourth approach a new method based on triplets of hits was developped for the ring detection. 

First of all it should be noted that especially the one, two and three dimensional Hough transforms were only superficially studied. Their study served more of an introduction into the Hough transform by adding extra dimensions for each case. The statements regarding these methods should always be considered with this in mind.

The 1D Hough transform assumes the number of rings and ring centers are known and searches for maximas in the r distribution for each rings.
It is a very stable method having no trouble to find different rings in different kinds of set ups. Even high background does not seem to impede the efficiency of the method. It is also a faster than all the other approaches since it only has to search a one dimensional histogram.

The 2D Hough transform assumes the number of rings and radiuses are known and searches for maxima in the ($x,y$) distribution for each ring. It shows a good performance as well but it suffers from lower speed due to the increased complexity namely searching
2 dimension for the parameters instead of just one. Another problem is also the misidentification of rings based on the order in which
they are searched for and possibly also the sensitivity of the weight function used to weigh the centers for a given data points and radius.

The 3D Hough transform does not make any assumptions on the number of rings or ring parameters. The main weakness
of this method is the score threshold which tells the algorithm when to stop looking for a ring (the 1D and 2D transform did not
have this problem since due to the information given it was known, how many rings there were). If the threshold is too low, too many 
fake rings can be formed by random combinations of (background) hits. - if it's too high a valid ring might get lost. The difficulty in defining a score threshold is 
that it is based on the scoring function \ref{eq:weight_function}. Depending on the $\sigma$ chosen the scoring function can behave
quite differently. A problem related to that is that the 3D Hough transform strongly depends on the bin size of the parameter space.
The bins should not be large big or the algorithm becomes inaccurate because the scoring function uses inaccurate values. If the bins are too
small, the algorithm takes forever due to the $\mathcal{O}(N^3)$ complexity. But the disadvantage can also have advantages because
now the algorithm does not depend anymore on the order of which it looks for rings - it always picks the strongest candidates first
and every subsequent candidate has a lower score until the score is so low that it's unlikely that it is a ring.

Finally the main part of this thesis discusses the combinatorial triplet Hough transform. It is based on the fact that 3 points define a ring.
Given 3 points in a 2D space it is possible to calculate the center and radius of the ring on which these 3 points lie. Given a list
of points a creating a list of all possible triplets can be used to find possible rings. The algorithm works very well and maintains a high efficiency
with all tested parameters but suffers as the 3D Hough transform from a high runtime (up to several minutes). However given the high accuracy
of the algorithm in determining the ring parameters makes this approach still very interesting and may offer potential for future investigations.
The parameter with the largest impact is the ring finding threshold which defines how many points need to lie on a ring in order to qualify as a 
circle candidate. Choosing this threshold too low many fake circles appear and the ghost rate skyrockets. Setting this threshold too high
means an inherent loss of efficiency from which the algorithm can never recover since circles with a point count lower than the threshold
will never be considered as a candidate.

\section{Outlook} % (fold)
\label{sec:outlook}
As a next step the possibility of parallelising the algorithm should be considered. Once the two triplet lists are generated the radius and centers
for these triplets can be calculated independently.
Other options for optimisation would be improving the code. Some steps have already been done. For example instead of using the \texttt{np.linalg.norm} function of the numpy module (which has a high overhead see \cite{NumpyNorm}) a simple norm function has been implemented. There was not enough time to test the speed improvement systematically but a profiling of one event showed an improvement of the speed from $188$\,s to $95$\,s. In general, the method where
radius and center of triplets get calculated would be a good start to optimise the code since that's the place where the algorithm spends most of
 its time (shown by profiling the python script but not shown in this thesis).
% section outlook (end)
% chapter conclusions (end)

\printbibliography
\end{document}
